export const testDocs = [
	{
		pageContent:
			"Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Get started [/docs/get_started]\n * Introduction\n\n\nINTRODUCTION\n\nLangChain is a framework for developing applications powered by language models. It enables applications that:\n\n * Are context-aware: connect a language model to other sources of context (prompt instructions, few shot examples, content to\n   ground it's response in)\n * Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc)\n\nThe main value props of LangChain are:\n\n 1. Components: abstractions for working with language models, along with a collection of implementations for each abstraction.\n    Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\n 2. Off-the-shelf chains: a structured assembly of components for accomplishing specific higher-level tasks\n\nOff-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to\ncustomize existing chains or build new ones.\n\n\nGET STARTED\n\nHere‚Äôs [/docs/get_started/installation] how to install LangChain, set up your environment, and start building.\n\nWe recommend following our Quickstart [/docs/get_started/quickstart] guide to familiarize yourself with the framework by building\nyour first LangChain application.\n\nNote: These docs are for the LangChain JS/TS package [https://github.com/hwchase17/langchainjs]. For documentation on the Python\nversion [https://github.com/hwchase17/langchain], head here [https://python.langchain.com/docs].\n\n\nMODULES\n\nLangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most\ncomplex:\n\nMODEL I/O [/docs/modules/model_io/]\n\nInterface with language models\n\nRETRIEVAL [/docs/modules/data_connection/]\n\nInterface with application-specific data\n\nCHAINS [/docs/modules/chains/]\n\nConstruct sequences of calls\n\nAGENTS [/docs/modules/agents/]\n\nLet chains choose which tools to use given high-level directives\n\nMEMORY [/docs/modules/memory/]\n\nPersist application state between runs of a chain\n\nCALLBACKS [/docs/modules/callbacks/]\n\nLog and stream intermediate steps of any chain\n\n\nEXAMPLES, ECOSYSTEM, AND RESOURCES\n\n\nUSE CASES [/docs/use_cases/]\n\nWalkthroughs and best-practices for common end-to-end use cases, like:\n\n * Chatbots [/docs/use_cases/chatbots/]\n * Answering questions using sources [/docs/use_cases/question_answering/]\n * Analyzing structured data [/docs/use_cases/tabular]\n * and much more...\n\n\nGUIDES [/docs/guides/]\n\nLearn best practices for developing with LangChain.\n\n\nADDITIONAL RESOURCES [/docs/additional_resources/]\n\nOur community is full of prolific developers, creative builders, and fantastic teachers. Check out Scrimba\n[/docs/additional_resources/scrimba] for a series of interactive guides on how to get started with various concepts, and Gallery\n[https://github.com/kyrolabs/awesome-langchain] for a list of awesome LangChain projects, compiled by the folks at KyroLabs\n[https://kyrolabs.com].\n\n\nCOMMUNITY [/docs/community]\n\nHead to the Community navigator [/docs/community] to find places to ask questions, share feedback, meet other developers, and\ndream about the future of LLM‚Äôs.\n\nPrevious\nGet started\n[/docs/get_started]\nNext\nInstallation\n[/docs/get_started/installation]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.",
		metadata: {
			source: 'https://js.langchain.com/docs/get_started/introduction',
			title: 'Introduction | ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent: '',
		metadata: {
			source: 'https://js.langchain.com/',
			title: 'ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Use cases [/docs/use_cases]\n   * QA and Chat over Documents [/docs/use_cases/question_answering/]\n   * Tabular Question Answering [/docs/use_cases/tabular]\n   * Interacting with APIs [/docs/use_cases/api]\n   * Summarization [/docs/use_cases/summarization]\n   * Agent Simulations [/docs/use_cases/agent_simulations/]\n   * Autonomous Agents [/docs/use_cases/autonomous_agents/]\n   * Chatbots [/docs/use_cases/chatbots]\n   * Extraction [/docs/use_cases/extraction]\n\n * /\n * Use cases\n\n\nUSE CASES\n\nWalkthroughs of common end-to-end use cases\n\n\nüóÉÔ∏è QA AND CHAT OVER DOCUMENTS\n\n2 items\n\n[/docs/use_cases/question_answering/]\n\n\nüìÑÔ∏è TABULAR QUESTION ANSWERING\n\nLots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables.\n\n[/docs/use_cases/tabular]\n\n\nüìÑÔ∏è INTERACTING WITH APIS\n\nLots of data and information is stored behind APIs.\n\n[/docs/use_cases/api]\n\n\nüìÑÔ∏è SUMMARIZATION\n\nA common use case is wanting to summarize long documents.\n\n[/docs/use_cases/summarization]\n\n\nüóÉÔ∏è AGENT SIMULATIONS\n\n1 items\n\n[/docs/use_cases/agent_simulations/]\n\n\nüóÉÔ∏è AUTONOMOUS AGENTS\n\n3 items\n\n[/docs/use_cases/autonomous_agents/]\n\n\nüìÑÔ∏è CHATBOTS\n\nLanguage models are good at producing text, which makes them ideal for creating chatbots.\n\n[/docs/use_cases/chatbots]\n\n\nüìÑÔ∏è EXTRACTION\n\nMost APIs and databases still deal with structured information. Therefore, in order to better work with those, it can be useful to\nextract structured information from text. Examples of this include:\n\n[/docs/use_cases/extraction]\nNext\nQA and Chat over Documents\n[/docs/use_cases/question_answering/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/use_cases',
			title: 'Use cases | ü¶úÔ∏èüîó Langchain',
			description: 'Walkthroughs of common end-to-end use cases',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Get started\n\n\nGET STARTED\n\nGet started with LangChain\n\n\nüìÑÔ∏è INTRODUCTION\n\n[/docs/get_started/introduction]\n\n\nüìÑÔ∏è INSTALLATION\n\n[/docs/get_started/installation]\n\n\nüìÑÔ∏è QUICKSTART\n\nInstallation\n\n[/docs/get_started/quickstart]\nNext\nIntroduction\n[/docs/get_started/introduction]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/get_started',
			title: 'Get started | ü¶úÔ∏èüîó Langchain',
			description: 'Get started with LangChain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Get started [/docs/get_started]\n * Installation\n\n\nINSTALLATION\n\ninfo\n\nUpdating from <0.0.52? See this section for instructions.\n\n\nSUPPORTED ENVIRONMENTS\n\nLangChain is written in TypeScript and can be used in:\n\n * Node.js (ESM and CommonJS) - 18.x, 19.x, 20.x\n * Cloudflare Workers\n * Vercel / Next.js (Browser, Serverless and Edge functions)\n * Supabase Edge Functions\n * Browser\n * Deno\n * Bun\n\n\nINSTALLATION\n\nTo get started, install LangChain with the following command:\n\n * npm\n * Yarn\n * pnpm\n\nnpm install -S langchain\n\n\n\n\nyarn add langchain\n\n\n\n\npnpm add langchain\n\n\n\n\n\nTYPESCRIPT\n\nLangChain is written in TypeScript and provides type definitions for all of its public APIs.\n\n\nLOADING THE LIBRARY\n\n\nESM\n\nLangChain provides an ESM build targeting Node.js environments. You can import it using the following syntax:\n\nimport { OpenAI } from "langchain/llms/openai";\n\n\n\n\nIf you are using TypeScript in an ESM project we suggest updating your tsconfig.json to include the following:\n\ntsconfig.json\n\n{\n  "compilerOptions": {\n    ...\n    "target": "ES2020", // or higher\n    "module": "nodenext",\n  }\n}\n\n\n\n\n\nCOMMONJS\n\nLangChain provides a CommonJS build targeting Node.js environments. You can import it using the following syntax:\n\nconst { OpenAI } = require("langchain/llms/openai");\n\n\n\n\n\nCLOUDFLARE WORKERS\n\nLangChain can be used in Cloudflare Workers. You can import it using the following syntax:\n\nimport { OpenAI } from "langchain/llms/openai";\n\n\n\n\n\nVERCEL / NEXT.JS\n\nLangChain can be used in Vercel / Next.js. We support using LangChain in frontend components, in Serverless functions and in Edge\nfunctions. You can import it using the following syntax:\n\nimport { OpenAI } from "langchain/llms/openai";\n\n\n\n\n\nDENO / SUPABASE EDGE FUNCTIONS\n\nLangChain can be used in Deno / Supabase Edge Functions. You can import it using the following syntax:\n\nimport { OpenAI } from "https://esm.sh/langchain/llms/openai";\n\n\n\n\nWe recommend looking at our Supabase Template [https://github.com/langchain-ai/langchain-template-supabase] for an example of how\nto use LangChain in Supabase Edge Functions.\n\n\nBROWSER\n\nLangChain can be used in the browser. In our CI we test bundling LangChain with Webpack and Vite, but other bundlers should work\ntoo. You can import it using the following syntax:\n\nimport { OpenAI } from "langchain/llms/openai";\n\n\n\n\n\nUPDATING FROM <0.0.52\n\nIf you are updating from a version of LangChain prior to 0.0.52, you will need to update your imports to use the new path\nstructure.\n\nFor example, if you were previously doing\n\nimport { OpenAI } from "langchain/llms";\n\n\n\n\nyou will now need to do\n\nimport { OpenAI } from "langchain/llms/openai";\n\n\n\n\nThis applies to all imports from the following 6 modules, which have been split into submodules for each integration. The combined\nmodules are deprecated, do not work outside of Node.js, and will be removed in a future version.\n\n * If you were using langchain/llms, see LLMs [/docs/modules/model_io/models/llms] for updated import paths.\n * If you were using langchain/chat_models, see Chat Models [/docs/modules/model_io/models/chat] for updated import paths.\n * If you were using langchain/embeddings, see Embeddings [/docs/modules/data_connection/text_embedding] for updated import paths.\n * If you were using langchain/vectorstores, see Vector Stores [/docs/modules/data_connection/vectorstores] for updated import\n   paths.\n * If you were using langchain/document_loaders, see Document Loaders [/docs/modules/data_connection/document_loaders] for updated\n   import paths.\n * If you were using langchain/retrievers, see Retrievers [/docs/modules/data_connection/retrievers] for updated import paths.\n\nOther modules are not affected by this change, and you can continue to import them from the same path.\n\nAdditionally, there are some breaking changes that were needed to support new environments:\n\n * import { Calculator } from "langchain/tools"; now moved to\n   * import { Calculator } from "langchain/tools/calculator";\n * import { loadLLM } from "langchain/llms"; now moved to\n   * import { loadLLM } from "langchain/llms/load";\n * import { loadAgent } from "langchain/agents"; now moved to\n   * import { loadAgent } from "langchain/agents/load";\n * import { loadPrompt } from "langchain/prompts"; now moved to\n   * import { loadPrompt } from "langchain/prompts/load";\n * import { loadChain } from "langchain/chains"; now moved to\n   * import { loadChain } from "langchain/chains/load";\n\n\nUNSUPPORTED: NODE.JS 16\n\nWe do not support Node.js 16, but if you still want to run LangChain on Node.js 16, you will need to follow the instructions in\nthis section. We do not guarantee that these instructions will continue to work in the future.\n\nYou will have to make fetch available globally, either:\n\n * run your application with NODE_OPTIONS=\'--experimental-fetch\' node ..., or\n * install node-fetch and follow the instructions here [https://github.com/node-fetch/node-fetch#providing-global-access]\n\nYou\'ll also need to polyfill ReadableStream [https://www.npmjs.com/package/web-streams-polyfill] by installing:\n\nnpm i web-streams-polyfill\n\n\n\n\nAnd then adding it to the global namespace in your main entrypoint:\n\nimport "web-streams-polyfill/es6"\n\n\n\n\nAdditionally you\'ll have to polyfill structuredClone, eg. by installing core-js and following the instructions here\n[https://github.com/zloirock/core-js].\n\nIf you are running Node.js 18+, you do not need to do anything.\n\nPrevious\nIntroduction\n[/docs/get_started/introduction]\nNext\nQuickstart\n[/docs/get_started/quickstart]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/get_started/installation',
			title: 'Installation | ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Get started [/docs/get_started]\n * Quickstart\n\nOn this page\n\n\nQUICKSTART\n\n\nINSTALLATION\n\nTo install LangChain run:\n\n * npm\n * Yarn\n * pnpm\n\nnpm install -S langchain\n\n\n\n\nyarn add langchain\n\n\n\n\npnpm add langchain\n\n\n\n\nFor more details, see our Installation guide [/docs/get_started/installation].\n\n\nENVIRONMENT SETUP\n\nUsing LangChain will usually require integrations with one or more model providers, data stores, APIs, etc. For this example,\nwe\'ll use OpenAI\'s model APIs.\n\nAccessing their API requires an API key, which you can get by creating an account and heading here\n[https://platform.openai.com/account/api-keys]. Once we have a key we\'ll want to set it as an environment variable by running:\n\nexport OPENAI_API_KEY="..."\n\n\n\n\nIf you\'d prefer not to set an environment variable you can pass the key in directly via the openAIApiKey parameter when\ninitializing the OpenAI LLM class:\n\nimport { OpenAI } from "langchain/llms/openai";\n\nconst llm = new OpenAI({\n  openAIApiKey: "YOUR_KEY_HERE",\n});\n\n\n\n\n\nBUILDING AN APPLICATION\n\nNow we can start building our language model application. LangChain provides many modules that can be used to build language model\napplications. Modules can be used as stand-alones in simple applications and they can be combined for more complex use cases.\n\nThe most common and most important chain that LangChain helps create contains three things:\n\n * LLM: The language model is the core reasoning engine here. In order to work with LangChain, you need to understand the\n   different types of language models and how to work with them.\n * Prompt Templates: This provides instructions to the language model. This controls what the language model outputs, so\n   understanding how to construct prompts and different prompting strategies is crucial.\n * Output Parsers: These translate the raw response from the LLM to a more workable format, making it easy to use the output\n   downstream.\n\nIn this getting started guide we will cover those three components by themselves, and then go over how to combine all of them.\nUnderstanding these concepts will set you up well for being able to use and customize LangChain applications. Most LangChain\napplications allow you to configure the LLM and/or the prompt used, so knowing how to take advantage of this will be a big\nenabler.\n\n\nLLMS\n\nThere are two types of language models, which in LangChain are called:\n\n * LLMs: this is a language model which takes a string as input and returns a string\n * ChatModels: this is a language model which takes a list of messages as input and returns a message\n\nThe input/output for LLMs is simple and easy to understand - a string. But what about ChatModels? The input there is a list of\nChatMessages, and the output is a single ChatMessage. A ChatMessage has two required components:\n\n * content: This is the content of the message.\n * role: This is the role of the entity from which the ChatMessage is coming from.\n\nLangChain provides several objects to easily distinguish between different roles:\n\n * HumanMessage: A ChatMessage coming from a human/user.\n * AIMessage: A ChatMessage coming from an AI/assistant.\n * SystemMessage: A ChatMessage coming from the system.\n * FunctionMessage: A ChatMessage coming from a function call.\n\nIf none of those roles sound right, there is also a ChatMessage class where you can specify the role manually. For more\ninformation on how to use these different messages most effectively, see our prompting guide.\n\nLangChain provides a standard interface for both, but it\'s useful to understand this difference in order to construct prompts for\na given language model. The standard interface that LangChain provides has two methods:\n\n * predict: Takes in a string, returns a string\n * predictMessages: Takes in a list of messages, returns a message.\n\nLet\'s see how to work with these different types of models and these different types of inputs. First, let\'s import an LLM and a\nChatModel and call predict.\n\nimport { OpenAI } from "langchain/llms/openai";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst llm = new OpenAI({\n  temperature: 0.9,\n});\n\nconst chatModel = new ChatOpenAI();\n\nconst text = "What would be a good company name for a company that makes colorful socks?";\n\nconst llmResult = await llm.predict(text);\n/*\n  "Feetful of Fun"\n*/\n\nconst chatModelResult = await chatModel.predict(text);\n/*\n  "Socks O\'Color"\n*/\n\n\n\n\nThe OpenAI and ChatOpenAI objects are basically just configuration objects. You can initialize them with parameters like\ntemperature and others, and pass them around.\n\nNext, let\'s use the predictMessages method to run over a list of messages.\n\nimport { HumanMessage } from "langchain/schema";\n\nconst text = "What would be a good company name for a company that makes colorful socks?";\n\nconst messages = [new HumanMessage({ content: text })];\n\nconst llmResult = await llm.predictMessages(messages);\n/*\n  AIMessage {\n    content: "Feetful of Fun"\n  }\n*/\n\nconst chatModelResult = await chatModel.predictMessages(messages);\n/*\n  AIMessage {\n    content: "Socks O\'Color"  \n  }\n*/\n\n\n\n\nFor both these methods, you can also pass in parameters as keyword arguments. For example, you could pass in temperature: 0 to\nadjust the temperature that is used from what the object was configured with. Whatever values are passed in during run time will\nalways override what the object was configured with.\n\n\nPROMPT TEMPLATES\n\nMost LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text,\ncalled a prompt template, that provides additional context on the specific task at hand.\n\nIn the previous example, the text we passed to the model contained instructions to generate a company name. For our application,\nit\'d be great if the user only had to provide the description of a company/product, without having to worry about giving the model\ninstructions.\n\nPromptTemplates help with exactly this! They bundle up all the logic for going from user input into a fully formatted prompt. This\ncan start off very simple - for example, a prompt to produce the above string would just be:\n\nimport { PromptTemplate } from "langchain/prompts";\n\nconst prompt = PromptTemplate.fromTemplate("What is a good name for a company that makes {product}?");\n\nconst formattedPrompt = await prompt.format({\n  product: "colorful socks",\n});\n/*\n  "What is a good name for a company that makes colorful socks?"\n*/\n\n\n\n\nThere are several advantages to using these over raw string formatting. You can "partial" out variables - e.g. you can format only\nsome of the variables at a time. You can compose them together, easily combining different templates into a single prompt. For\nexplanations of these functionalities, see the section on prompts [/docs/modules/model_io/prompts] for more detail.\n\nPromptTemplates can also be used to produce a list of messages. In this case, the prompt not only contains information about the\ncontent, but also each message (its role, its position in the list, etc). Here, what happens most often is a ChatPromptTemplate is\na list of ChatMessageTemplates. Each ChatMessageTemplate contains instructions for how to format that ChatMessage - its role, and\nthen also its content. Let\'s take a look at this below:\n\nimport { ChatPromptTemplate } from "langchain/prompts";\n\nconst template = "You are a helpful assistant that translates {input_language} to {output_language}.";\nconst humanTemplate = "{text}";\n\nconst chatPrompt = ChatPromptTemplate.fromMessages([\n  ["system", template],\n  ["human", humanTemplate],\n]);\n\nconst formattedChatPrompt = await chatPrompt.formatMessages({\n  input_language: "English",\n  output_language: "French",\n  text: "I love programming.",\n});\n\n/*\n  [\n    SystemMessage {\n      content: \'You are a helpful assistant that translates English to French.\'\n    },\n    HumanMessage { content: \'I love programming.\' }\n  ]\n*/\n\n\n\n\nChatPromptTemplates can also be constructed in other ways - see the section on prompts [/docs/modules/model_io/prompts] for more\ndetail.\n\n\nOUTPUT PARSERS\n\nOutputParsers convert the raw output of an LLM into a format that can be used downstream. There are few main type of\nOutputParsers, including:\n\n * Convert text from LLM -> structured information (e.g. JSON)\n * Convert a ChatMessage into just a string\n * Convert the extra information returned from a call besides the message (like OpenAI function invocation) into a string.\n\nFor more information, see the section on output parsers [/docs/modules/model_io/output_parsers].\n\nIn this getting started guide, we will write our own output parser - one that converts a comma separated list into a list.\n\nimport { BaseOutputParser } from "langchain/schema/output_parser";\n\n/**\n * Parse the output of an LLM call to a comma-separated list.\n */\nclass CommaSeparatedListOutputParser extends BaseOutputParser<string[]> {\n  async parse(text: string): Promise<string[]> {\n    return text.split(",").map((item) => item.trim());\n  }\n}\n\nconst parser = new CommaSeparatedListOutputParser();\n\nconst result = await parser.parse("hi, bye");\n/* \n  [\'hi\', \'bye\']\n*/\n\n\n\n\n\nPROMPTTEMPLATE + LLM + OUTPUTPARSER\n\nWe can now combine all these into one chain. This chain will take input variables, pass those to a prompt template to create a\nprompt, pass the prompt to a language model, and then pass the output through an (optional) output parser. This is a convenient\nway to bundle up a modular piece of logic. Let\'s see it in action!\n\nimport { ChatOpenAI } from "langchain/chat_models/openai";\nimport { ChatPromptTemplate } from "langchain/prompts";\nimport { BaseOutputParser } from "langchain/schema/output_parser";\n\n/**\n * Parse the output of an LLM call to a comma-separated list.\n */\nclass CommaSeparatedListOutputParser extends BaseOutputParser<string[]> {\n  async parse(text: string): Promise<string[]> {\n    return text.split(",").map((item) => item.trim());\n  }\n}\n\nconst template = `You are a helpful assistant who generates comma separated lists.\nA user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\nONLY return a comma separated list, and nothing more.`;\n\nconst humanTemplate = "{text}";\n\n/**\n * Chat prompt for generating comma-separated lists. It combines the system\n * template and the human template.\n */\nconst chatPrompt = ChatPromptTemplate.fromMessages(\n  [\n    ["system", template],\n    ["human", humanTemplate],\n  ]\n);\n\nconst model = new ChatOpenAI({});\nconst parser = new CommaSeparatedListOutputParser();\n\nconst chain = chatPrompt.pipe(model).pipe(parser);\n\nconst result = await chain.invoke({\n  text: "colors",\n});\n\n/*\n  ["red", "blue", "green", "yellow", "orange"]\n*/\n\n\n\n\nNote that we are using the .pipe() method to join these components together. This .pipe() method is part of the LangChain\nExpression Language. To learn more about this syntax, read the documentation here [/docs/expression_language].\n\n\nNEXT STEPS\n\nAnd that\'s it for the quickstart! We\'ve now gone over how to create the core building block of LangChain applications. There is a\nlot more nuance in all these components (LLMs, prompts, output parsers) and a lot more different components to learn about as\nwell. To continue on your journey:\n\n * Dive deeper [/docs/modules/model_io] into LLMs, prompts, and output parsers\n * Learn the other key components [/docs/modules]\n * Read up on LangChain Expression Language [/docs/expression_language] to learn how to chain these components together\n * Check out our helpful guides [/docs/guides] for detailed walkthroughs on particular topics\n * Explore end-to-end use cases [/docs/use_cases/]\n\nPrevious\nInstallation\n[/docs/get_started/installation]\nNext\nModules\n[/docs/modules/]\n * Installation\n * Environment setup\n * Building an application\n * LLMs\n * Prompt templates\n * Output parsers\n * PromptTemplate + LLM + OutputParser\n * Next steps\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/get_started/quickstart',
			title: 'Quickstart | ü¶úÔ∏èüîó Langchain',
			description: 'Installation',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules\n\nOn this page\n\n\nMODULES\n\nLangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most\ncomplex:\n\nMODEL I/O [/docs/modules/model_io/]\n\nInterface with language models\n\nDATA CONNECTION [/docs/modules/data_connection/]\n\nInterface with application-specific data\n\nCHAINS [/docs/modules/chains/]\n\nConstruct sequences of calls\n\nAGENTS [/docs/modules/agents/]\n\nLet chains choose which tools to use given high-level directives\n\nMEMORY [/docs/modules/memory/]\n\nPersist application state between runs of a chain\n\nCALLBACKS [/docs/modules/callbacks/]\n\nLog and stream intermediate steps of any chain\n\nPrevious\nQuickstart\n[/docs/get_started/quickstart]\nNext\nModel I/O\n[/docs/modules/model_io/]\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/modules/',
			title: 'Modules | ü¶úÔ∏èüîó Langchain',
			description:
				'LangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex:',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n     * Prompts [/docs/modules/model_io/prompts/]\n     * Language models [/docs/modules/model_io/models/]\n     * Output parsers [/docs/modules/model_io/output_parsers/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Model I/ O\n\n\nMODEL I/O\n\nThe core element of any language model application is...the model. LangChain gives you the building blocks to interface with any\nlanguage model.\n\n * Prompts [/docs/modules/model_io/prompts/]: Templatize, dynamically select, and manage model inputs\n * Language models [/docs/modules/model_io/models/]: Make calls to language models through common interfaces\n * Output parsers [/docs/modules/model_io/output_parsers/]: Extract information from model outputs\n\nmodel_io_diagram [/assets/images/model_io-1f23a36233d7731e93576d6885da2750.jpg]\n\nPrevious\nModules\n[/docs/modules/]\nNext\nPrompts\n[/docs/modules/model_io/prompts/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/modules/model_io/',
			title: 'Model I/O | ü¶úÔ∏èüîó Langchain',
			description:
				'The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model.',
			language: 'en'
		}
	},
	{
		pageContent:
			"Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n     * Document loaders [/docs/modules/data_connection/document_loaders/]\n     * Document transformers [/docs/modules/data_connection/document_transformers/]\n     * Text embedding models [/docs/modules/data_connection/text_embedding/]\n     * Vector stores [/docs/modules/data_connection/vectorstores/]\n     * Retrievers [/docs/modules/data_connection/retrievers/]\n     * Experimental [/docs/modules/data_connection/experimental/multimodal_embeddings/google_vertex_ai]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Retrieval\n\n\nRETRIEVAL\n\nMany LLM applications require user-specific data that is not part of the model's training set. The primary way of accomplishing\nthis is through Retrieval Augmented Generation (RAG). In this process, external data is retrieved and then passed to the LLM when\ndoing the generation step.\n\nLangChain provides all the building blocks for RAG applications - from simple to complex. This section of the documentation covers\neverything related to the retrieval step - e.g. the fetching of the data. Although this sounds simple, it can be subtly complex.\nThis encompasses several key modules.\n\ndata_connection_diagram [/assets/images/data_connection-c42d68c3d092b85f50d08d4cc171fc25.jpg]\n\nDocument loaders [/docs/modules/data_connection/document_loaders/]\n\nLoad documents from many different sources. LangChain provides many different document loaders as well as integrations with other\nmajor providers in the space, such as Unstructured. We provide integrations to load all types of documents (html, PDF, code) from\nall types of locations (private s3 buckets, public websites).\n\nDocument transformers [/docs/modules/data_connection/document_transformers/]\n\nA key part of retrieval is fetching only the relevant parts of documents. This involves several transformation steps in order to\nbest prepare the documents for retrieval. One of the primary ones here is splitting (or chunking) a large document into smaller\nchunks. LangChain provides several different algorithms for doing this, as well as logic optimized for specific document types\n(code, markdown, etc).\n\nText embedding models [/docs/modules/data_connection/text_embedding/]\n\nAnother key part of retrieval has become creating embeddings for documents. Embeddings capture the semantic meaning of text,\nallowing you to quickly and efficiently find other pieces of text that are similar. LangChain provides integrations with different\nembedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs.\nLangChain exposes a standard interface, allowing you to easily swap between models.\n\nVector stores [/docs/modules/data_connection/vectorstores/]\n\nWith the rise of embeddings, there has emerged a need for databases to support efficient storage and searching of these\nembeddings. LangChain provides integrations with many different vectorstores, from open-source local ones to cloud-hosted\nproprietary ones, allowing you choose the one best suited for your needs. LangChain exposes a standard interface, allowing you to\neasily swap between vector stores.\n\nRetrievers [/docs/modules/data_connection/retrievers/]\n\nOnce the data is in the database, you still need to retrieve it. LangChain supports many different retrieval algorithms and is one\nof the places where we add the most value. We support basic methods that are easy to get started - namely simple semantic search.\nHowever, we have also added a collection of algorithms on top of this to increase performance. These include:\n\n * Parent Document Retriever [/docs/modules/data_connection/retrievers/how_to/parent-document-retriever]: This allows you to\n   create multiple embeddings per parent document, allowing you to look up smaller chunks but return larger context.\n * Self Query Retriever [/docs/modules/data_connection/retrievers/how_to/self_query]: User questions often contain reference to\n   something that isn't just semantic, but rather expresses some logic that can best be represented as a metadata filter.\n   Self-query allows you to parse out the semantic part of a query from other metadata filters present in the query\n * And more!\n\nPrevious\nStructured output parser\n[/docs/modules/model_io/output_parsers/structured]\nNext\nDocument loaders\n[/docs/modules/data_connection/document_loaders/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.",
		metadata: {
			source: 'https://js.langchain.com/docs/modules/data_connection/',
			title: 'Retrieval | ü¶úÔ∏èüîó Langchain',
			description:
				"Many LLM applications require user-specific data that is not part of the model's training set.",
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n     * How to [/docs/modules/chains/how_to/]\n     * Foundational [/docs/modules/chains/foundational/]\n     * Documents [/docs/modules/chains/document/]\n     * Popular [/docs/modules/chains/popular/]\n     * Additional [/docs/modules/chains/additional/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Chains\n\nOn this page\n\n\nCHAINS\n\nUsing an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each\nother or with other components.\n\nLangChain provides the Chain interface for such "chained" applications. We define a Chain very generically as a sequence of calls\nto components, which can include other chains. The base interface is simple:\n\nimport { CallbackManagerForChainRun } from "langchain/callbacks";\nimport { BaseChain as _ } from "langchain/chains";\nimport { BaseMemory } from "langchain/memory";\nimport { ChainValues } from "langchain/schema";\n\nabstract class BaseChain {\n  memory?: BaseMemory;\n\n  /**\n   * Run the core logic of this chain and return the output\n   */\n  abstract _call(\n    values: ChainValues,\n    runManager?: CallbackManagerForChainRun\n  ): Promise<ChainValues>;\n\n  /**\n   * Return the string type key uniquely identifying this class of chain.\n   */\n  abstract _chainType(): string;\n\n  /**\n   * Return the list of input keys this chain expects to receive when called.\n   */\n  abstract get inputKeys(): string[];\n\n  /**\n   * Return the list of output keys this chain will produce when called.\n   */\n  abstract get outputKeys(): string[];\n}\n\n\n\n\nAPI REFERENCE:\n\n * CallbackManagerForChainRun [/docs/api/callbacks/classes/CallbackManagerForChainRun] from langchain/callbacks\n * BaseChain [/docs/api/chains/classes/BaseChain] from langchain/chains\n * BaseMemory [/docs/api/memory/classes/BaseMemory] from langchain/memory\n * ChainValues [/docs/api/schema/types/ChainValues] from langchain/schema\n\nThis idea of composing components together in a chain is simple but powerful. It drastically simplifies and makes more modular the\nimplementation of complex applications, which in turn makes it much easier to debug, maintain, and improve your applications.\n\nFor more specifics check out:\n\n * How-to [/docs/modules/chains/how_to/] for walkthroughs of different chain features\n * Foundational [/docs/modules/chains/foundational/] to get acquainted with core building block chains\n * Document [/docs/modules/chains/document/] to learn how to incorporate documents into chains\n * Popular [/docs/modules/chains/popular/] chains for the most common use cases\n * Additional [/docs/modules/chains/additional/] to see some of the more advanced chains and integrations that you can use out of\n   the box\n\n\nWHY DO WE NEED CHAINS?\n\nChains allow us to combine multiple components together to create a single, coherent application. For example, we can create a\nchain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more\ncomplex chains by combining multiple chains together, or by combining chains with other components.\n\n\nGET STARTED\n\n\nUSING LLMCHAIN\n\nThe LLMChain is most basic building block chain. It takes in a prompt template, formats it with the user input and returns the\nresponse from an LLM.\n\nTo use the LLMChain, first create a prompt template.\n\nimport { OpenAI } from "langchain/llms/openai";\nimport { PromptTemplate } from "langchain/prompts";\nimport { LLMChain } from "langchain/chains";\n\n// We can construct an LLMChain from a PromptTemplate and an LLM.\nconst model = new OpenAI({ temperature: 0 });\nconst prompt = PromptTemplate.fromTemplate(\n  "What is a good name for a company that makes {product}?"\n);\n\n\n\n\nWe can now create a very simple chain that will take user input, format the prompt with it, and then send it to the LLM.\n\nconst chain = new LLMChain({ llm: model, prompt });\n\n// Since this LLMChain is a single-input, single-output chain, we can also `run` it.\n// This convenience method takes in a string and returns the value\n// of the output key field in the chain response. For LLMChains, this defaults to "text".\nconst res = await chain.run("colorful socks");\nconsole.log({ res });\n\n// { res: "\\n\\nSocktastic!" }\n\n\n\n\nIf there are multiple variables, you can input them all at once using a dictionary. This will return the complete chain response.\n\nconst prompt = PromptTemplate.fromTemplate(\n  "What is a good name for {company} that makes {product}?"\n);\n\nconst chain = new LLMChain({ llm: model, prompt });\n\nconst res = await chain.call({\n  company: "a startup",\n  product: "colorful socks"\n});\n\nconsole.log({ res });\n// { res: { text: \'\\n\\Socktopia Colourful Creations.\' } }\n\n\n\n\nYou can use a chat model in an LLMChain as well:\n\nimport { ChatPromptTemplate } from "langchain/prompts";\nimport { LLMChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\n// We can also construct an LLMChain from a ChatPromptTemplate and a chat model.\nconst chat = new ChatOpenAI({ temperature: 0 });\nconst chatPrompt = ChatPromptTemplate.fromMessages([\n  [\n    "system",\n    "You are a helpful assistant that translates {input_language} to {output_language}.",\n  ],\n  ["human", "{text}"],\n]);\nconst chainB = new LLMChain({\n  prompt: chatPrompt,\n  llm: chat,\n});\n\nconst resB = await chainB.call({\n  input_language: "English",\n  output_language: "French",\n  text: "I love programming.",\n});\nconsole.log({ resB });\n// { resB: { text: "J\'adore la programmation." } }\n\n\n\n\nAPI REFERENCE:\n\n * ChatPromptTemplate [/docs/api/prompts/classes/ChatPromptTemplate] from langchain/prompts\n * LLMChain [/docs/api/chains/classes/LLMChain] from langchain/chains\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n\nPrevious\nGoogle Vertex AI\n[/docs/modules/data_connection/experimental/multimodal_embeddings/google_vertex_ai]\nNext\nHow to\n[/docs/modules/chains/how_to/]\n * Why do we need chains?\n * Get started\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/modules/chains/',
			title: 'Chains | ü¶úÔ∏èüîó Langchain',
			description: 'Using an LLM in isolation is fine for simple applications,',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n     * How-to [/docs/modules/memory/how_to/buffer]\n     * Integrations [/docs/modules/memory/integrations/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Memory\n\nOn this page\n\n\nMEMORY\n\nüöß Docs under construction üöß\n\nBy default, Chains and Agents are stateless, meaning that they treat each incoming query independently (like the underlying LLMs\nand chat models themselves). In some applications, like chatbots, it is essential to remember previous interactions, both in the\nshort and long-term. The Memory class does exactly that.\n\nLangChain provides memory components in two forms. First, LangChain provides helper utilities for managing and manipulating\nprevious chat messages. These are designed to be modular and useful regardless of how they are used. Secondly, LangChain provides\neasy ways to incorporate these utilities into chains.\n\n\nGET STARTED\n\nMemory involves keeping a concept of state around throughout a user\'s interactions with a language model. A user\'s interactions\nwith a language model are captured in the concept of ChatMessages, so this boils down to ingesting, capturing, transforming and\nextracting knowledge from a sequence of chat messages. There are many different ways to do this, each of which exists as its own\nmemory type.\n\nIn general, for each type of memory there are two ways to understanding using memory. These are the standalone functions which\nextract information from a sequence of messages, and then there is the way you can use this type of memory in a chain.\n\nMemory can return multiple pieces of information (for example, the most recent N messages and a summary of all previous messages).\nThe returned information can either be a string or a list of messages.\n\nWe will walk through the simplest form of memory: "buffer" memory, which just involves keeping a buffer of all prior messages. We\nwill show how to use the modular utility functions here, then show how it can be used in a chain (both returning a string as well\nas a list of messages).\n\n\nCHATMESSAGEHISTORY\n\nOne of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super\nlightweight wrapper which exposes convenience methods for saving Human messages, AI messages, and then fetching them all.\n\nSubclassing this class allows you to use different storage solutions, such as Redis, to keep persistent chat message histories.\n\nimport { ChatMessageHistory } from "langchain/memory";\n\nconst history = new ChatMessageHistory();\n\nawait history.addUserMessage("Hi!");\n\nawait history.addAIChatMessage("What\'s up?");\n\nconst messages = await history.getMessages();\n\nconsole.log(messages);\n\n/*\n  [\n    HumanMessage {\n      content: \'Hi!\',\n    },\n    AIMessage {\n      content: "What\'s up?",\n    }\n  ]\n*/\n\n\n\n\nYou can also load messages into memory instances by creating and passing in a ChatHistory object. This lets you easily pick up\nstate from past conversations. In addition to the above technique, you can do:\n\nimport { BufferMemory, ChatMessageHistory } from "langchain/memory";\nimport { HumanChatMessage, AIChatMessage } from "langchain/schema";\n\nconst pastMessages = [\n  new HumanMessage("My name\'s Jonas"),\n  new AIMessage("Nice to meet you, Jonas!"),\n];\n\nconst memory = new BufferMemory({\n  chatHistory: new ChatMessageHistory(pastMessages),\n});\n\n\n\nnote\n\nDo not share the same history or memory instance between two different chains, a memory instance represents the history of a\nsingle conversation\n\nnote\n\nIf you deploy your LangChain app on a serverless environment do not store memory instances in a variable, as your hosting provider\nmay have reset it by the next time the function is called.\n\n\nBUFFERMEMORY\n\nWe now show how to use this simple concept in a chain. We first showcase BufferMemory, a wrapper around ChatMessageHistory that\nextracts the messages into an input variable.\n\nimport { OpenAI } from "langchain/llms/openai";\nimport { BufferMemory } from "langchain/memory";\nimport { ConversationChain } from "langchain/chains";\n\nconst model = new OpenAI({});\nconst memory = new BufferMemory();\n// This chain is preconfigured with a default prompt\nconst chain = new ConversationChain({ llm: model, memory: memory });\nconst res1 = await chain.call({ input: "Hi! I\'m Jim." });\nconsole.log({ res1 });\n\n\n\n\n{response: " Hi Jim! It\'s nice to meet you. My name is AI. What would you like to talk about?"}\n\n\n\n\nconst res2 = await chain.call({ input: "What\'s my name?" });\nconsole.log({ res2 });\n\n\n\n\n{response: \' You said your name is Jim. Is there anything else you would like to talk about?\'}\n\n\n\n\nThere are plenty of different types of memory, check out our examples to see more!\n\n\nCREATING YOUR OWN MEMORY CLASS\n\nThe BaseMemory interface has two methods:\n\nexport type InputValues = Record<string, any>;\n\nexport type OutputValues = Record<string, any>;\n\ninterface BaseMemory {\n  loadMemoryVariables(values: InputValues): Promise<MemoryVariables>;\n\n  saveContext(\n    inputValues: InputValues,\n    outputValues: OutputValues\n  ): Promise<void>;\n}\n\n\n\n\nTo implement your own memory class you have two options:\n\n\nSUBCLASSING BASECHATMEMORY\n\nThis is the easiest way to implement your own memory class. You can subclass BaseChatMemory, which takes care of saveContext by\nsaving inputs and outputs as Chat Messages [/docs/api/schema/classes/BaseMessage], and implement only the loadMemoryVariables\nmethod. This method is responsible for returning the memory variables that are relevant for the current input values.\n\nabstract class BaseChatMemory extends BaseMemory {\n  chatHistory: ChatMessageHistory;\n\n  abstract loadMemoryVariables(values: InputValues): Promise<MemoryVariables>;\n}\n\n\n\n\n\nSUBCLASSING BASEMEMORY\n\nIf you want to implement a more custom memory class, you can subclass BaseMemory and implement both loadMemoryVariables and\nsaveContext methods. The saveContext method is responsible for storing the input and output values in memory. The\nloadMemoryVariables method is responsible for returning the memory variables that are relevant for the current input values.\n\nabstract class BaseMemory {\n  abstract loadMemoryVariables(values: InputValues): Promise<MemoryVariables>;\n\n  abstract saveContext(\n    inputValues: InputValues,\n    outputValues: OutputValues\n  ): Promise<void>;\n}\n\n\n\nPrevious\nDynamically selecting from multiple retrievers\n[/docs/modules/chains/additional/multi_retrieval_qa_router]\nNext\nConversation buffer memory\n[/docs/modules/memory/how_to/buffer]\n * Get started\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/modules/memory/',
			title: 'Memory | ü¶úÔ∏èüîó Langchain',
			description: 'üöß Docs under construction üöß',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n     * Agent types [/docs/modules/agents/agent_types/]\n     * How-to [/docs/modules/agents/how_to/callbacks]\n     * Tools [/docs/modules/agents/tools/]\n     * Toolkits [/docs/modules/agents/toolkits/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Agents\n\nOn this page\n\n\nAGENTS\n\nSome applications require a flexible chain of calls to LLMs and other tools based on user input. The Agent interface provides the\nflexibility for such applications. An agent has access to a suite of tools, and determines which ones to use depending on the user\ninput. Agents can use multiple tools, and use the output of one tool as the input to the next.\n\nThere are two main types of agents:\n\n * Action agents: at each timestep, decide on the next action using the outputs of all previous actions\n * Plan-and-execute agents: decide on the full sequence of actions up front, then execute them all without updating the plan\n\nAction agents are suitable for small tasks, while plan-and-execute agents are better for complex or long-running tasks that\nrequire maintaining long-term objectives and focus. Often the best approach is to combine the dynamism of an action agent with the\nplanning abilities of a plan-and-execute agent by letting the plan-and-execute agent use action agents to execute plans.\n\nFor a full list of agent types see agent types [/docs/modules/agents/agent_types/]. Additional abstractions involved in agents\nare:\n\n * Tools [/docs/modules/agents/tools/]: the actions an agent can take. What tools you give an agent highly depend on what you want\n   the agent to do\n * Toolkits [/docs/modules/agents/toolkits/]: wrappers around collections of tools that can be used together a specific use case.\n   For example, in order for an agent to interact with a SQL database it will likely need one tool to execute queries and another\n   to inspect tables\n\n\nACTION AGENTS\n\nAt a high-level an action agent:\n\n 1. Receives user input\n 2. Decides which tool, if any, to use and the tool input\n 3. Calls the tool and records the output (also known as an "observation")\n 4. Decides the next step using the history of tools, tool inputs, and observations\n 5. Repeats 3-4 until it determines it can respond directly to the user\n\nAction agents are wrapped in agent executors, chains which are responsible for calling the agent, getting back an action and\naction input, calling the tool that the action references with the generated input, getting the output of the tool, and then\npassing all that information back into the agent to get the next action it should take.\n\nAlthough an agent can be constructed in many ways, it typically involves these components:\n\n * Prompt template: Responsible for taking the user input and previous steps and constructing a prompt to send to the language\n   model\n * Language model: Takes the prompt with user input and action history and decides what to do next\n * Output parser: Takes the output of the language model and parses it into the next action or a final answer\n\n\nPLAN-AND-EXECUTE AGENTS\n\nAt a high-level a plan-and-execute agent:\n\n 1. Receives user input\n 2. Plans the full sequence of steps to take\n 3. Executes the steps in order, passing the outputs of past steps as inputs to future steps\n\nThe most typical implementation is to have the planner be a language model, and the executor be an action agent. Read more here\n[/docs/modules/agents/agent_types/plan_and_execute].\n\n\nGET STARTED\n\nLangChain offers several types of agents. Here\'s an example using one powered by OpenAI functions:\n\nimport { initializeAgentExecutorWithOptions } from "langchain/agents";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\nimport { SerpAPI } from "langchain/tools";\nimport { Calculator } from "langchain/tools/calculator";\n\nconst tools = [new Calculator(), new SerpAPI()];\nconst chat = new ChatOpenAI({ modelName: "gpt-4", temperature: 0 });\n\nconst executor = await initializeAgentExecutorWithOptions(tools, chat, {\n  agentType: "openai-functions",\n  verbose: true,\n});\n\nconst result = await executor.run("What is the weather in New York?");\nconsole.log(result);\n\n/*\n  The current weather in New York is 72¬∞F with a wind speed of 1 mph coming from the SSW. The humidity is at 89% and the UV index is 0 out of 11. The cloud cover is 79% and there has been no rain.\n*/\n\n\n\n\nAPI REFERENCE:\n\n * initializeAgentExecutorWithOptions [/docs/api/agents/functions/initializeAgentExecutorWithOptions] from langchain/agents\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n * SerpAPI [/docs/api/tools/classes/SerpAPI] from langchain/tools\n * Calculator [/docs/api/tools_calculator/classes/Calculator] from langchain/tools/calculator\n\nAnd here is the logged verbose output:\n\n[chain/start] [1:chain:AgentExecutor] Entering Chain run with input: {\n  "input": "What is the weather in New York?",\n  "chat_history": []\n}\n[llm/start] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input: {\n  "messages": [\n    [\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "SystemMessage"\n        ],\n        "kwargs": {\n          "content": "You are a helpful AI assistant.",\n          "additional_kwargs": {}\n        }\n      },\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "HumanMessage"\n        ],\n        "kwargs": {\n          "content": "What is the weather in New York?",\n          "additional_kwargs": {}\n        }\n      }\n    ]\n  ]\n}\n[llm/end] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.97s] Exiting LLM run with output: {\n  "generations": [\n    [\n      {\n        "text": "",\n        "message": {\n          "lc": 1,\n          "type": "constructor",\n          "id": [\n            "langchain",\n            "schema",\n            "AIMessage"\n          ],\n          "kwargs": {\n            "content": "",\n            "additional_kwargs": {\n              "function_call": {\n                "name": "search",\n                "arguments": "{\\n  \\"input\\": \\"current weather in New York\\"\\n}"\n              }\n            }\n          }\n        }\n      }\n    ]\n  ],\n  "llmOutput": {\n    "tokenUsage": {\n      "completionTokens": 18,\n      "promptTokens": 121,\n      "totalTokens": 139\n    }\n  }\n}\n[agent/action] [1:chain:AgentExecutor] Agent selected action: {\n  "tool": "search",\n  "toolInput": {\n    "input": "current weather in New York"\n  },\n  "log": ""\n}\n[tool/start] [1:chain:AgentExecutor > 3:tool:SerpAPI] Entering Tool run with input: "current weather in New York"\n[tool/end] [1:chain:AgentExecutor > 3:tool:SerpAPI] [1.90s] Exiting Tool run with output: "1 am ¬∑ Feels Like72¬∞ ¬∑ WindSSW 1 mph ¬∑ Humidity89% ¬∑ UV Index0 of 11 ¬∑ Cloud Cover79% ¬∑ Rain Amount0 in ..."\n[llm/start] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] Entering LLM run with input: {\n  "messages": [\n    [\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "SystemMessage"\n        ],\n        "kwargs": {\n          "content": "You are a helpful AI assistant.",\n          "additional_kwargs": {}\n        }\n      },\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "HumanMessage"\n        ],\n        "kwargs": {\n          "content": "What is the weather in New York?",\n          "additional_kwargs": {}\n        }\n      },\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "AIMessage"\n        ],\n        "kwargs": {\n          "content": "",\n          "additional_kwargs": {\n            "function_call": {\n              "name": "search",\n              "arguments": "{\\"input\\":\\"current weather in New York\\"}"\n            }\n          }\n        }\n      },\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain",\n          "schema",\n          "FunctionMessage"\n        ],\n        "kwargs": {\n          "content": "1 am ¬∑ Feels Like72¬∞ ¬∑ WindSSW 1 mph ¬∑ Humidity89% ¬∑ UV Index0 of 11 ¬∑ Cloud Cover79% ¬∑ Rain Amount0 in ...",\n          "name": "search",\n          "additional_kwargs": {}\n        }\n      }\n    ]\n  ]\n}\n[llm/end] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] [3.33s] Exiting LLM run with output: {\n  "generations": [\n    [\n      {\n        "text": "The current weather in New York is 72¬∞F with a wind speed of 1 mph coming from the SSW. The humidity is at 89% and the UV index is 0 out of 11. The cloud cover is 79% and there has been no rain.",\n        "message": {\n          "lc": 1,\n          "type": "constructor",\n          "id": [\n            "langchain",\n            "schema",\n            "AIMessage"\n          ],\n          "kwargs": {\n            "content": "The current weather in New York is 72¬∞F with a wind speed of 1 mph coming from the SSW. The humidity is at 89% and the UV index is 0 out of 11. The cloud cover is 79% and there has been no rain.",\n            "additional_kwargs": {}\n          }\n        }\n      }\n    ]\n  ],\n  "llmOutput": {\n    "tokenUsage": {\n      "completionTokens": 58,\n      "promptTokens": 180,\n      "totalTokens": 238\n    }\n  }\n}\n[chain/end] [1:chain:AgentExecutor] [7.73s] Exiting Chain run with output: {\n  "output": "The current weather in New York is 72¬∞F with a wind speed of 1 mph coming from the SSW. The humidity is at 89% and the UV index is 0 out of 11. The cloud cover is 79% and there has been no rain."\n}\n\n\n\nPrevious\nZep Memory\n[/docs/modules/memory/integrations/zep_memory]\nNext\nAgent types\n[/docs/modules/agents/agent_types/]\n * Action agents\n * Plan-and-execute agents\n * Get started\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/modules/agents/',
			title: 'Agents | ü¶úÔ∏èüîó Langchain',
			description:
				'Some applications require a flexible chain of calls to LLMs and other tools based on user input. The Agent interface provides the flexibility for such applications. An agent has access to a suite of tools, and determines which ones to use depending on the user input. Agents can use multiple tools, and use the output of one tool as the input to the next.',
			language: 'en'
		}
	},
	{
		pageContent:
			"Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n     * How-to [/docs/modules/callbacks/how_to/background_callbacks]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Modules [/docs/modules/]\n * Callbacks\n\n\nCALLBACKS\n\nLangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for\nlogging, monitoring, streaming, and other tasks.\n\nYou can subscribe to these events by using the callbacks argument available throughout the API. This method accepts a list of\nhandler objects, which are expected to implement one or more of the methods described in the API docs\n[/docs/api/callbacks/interfaces/CallbackHandlerMethods].\n\n\nHOW TO USE CALLBACKS\n\nThe callbacks argument is available on most objects throughout the API (Chains [/docs/modules/chains/], Language Models\n[/docs/modules/model_io/models/], Tools [/docs/modules/agents/tools/], Agents [/docs/modules/agents/], etc.) in two different\nplaces.\n\n\nCONSTRUCTOR CALLBACKS\n\nDefined in the constructor, eg. new LLMChain({ callbacks: [handler] }), which will be used for all calls made on that object, and\nwill be scoped to that object only, eg. if you pass a handler to the LLMChain constructor, it will not be used by the Model\nattached to that chain.\n\nimport { ConsoleCallbackHandler } from \"langchain/callbacks\";\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst llm = new OpenAI({\n  temperature: 0,\n  // These tags will be attached to all calls made with this LLM.\n  tags: [\"example\", \"callbacks\", \"constructor\"],\n  // This handler will be used for all calls made with this LLM.\n  callbacks: [new ConsoleCallbackHandler()],\n});\n\n\n\n\nAPI REFERENCE:\n\n * ConsoleCallbackHandler [/docs/api/callbacks/classes/ConsoleCallbackHandler] from langchain/callbacks\n * OpenAI [/docs/api/llms_openai/classes/OpenAI] from langchain/llms/openai\n\n\nREQUEST CALLBACKS\n\nDefined in the call()/run()/apply() methods used for issuing a request, eg. chain.call({ input: '...' }, [handler]), which will be\nused for that specific request only, and all sub-requests that it contains (eg. a call to an LLMChain triggers a call to a Model,\nwhich uses the same handler passed in the call() method).\n\nimport { ConsoleCallbackHandler } from \"langchain/callbacks\";\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst llm = new OpenAI({\n  temperature: 0,\n});\n\nconst response = await llm.call(\"1 + 1 =\", {\n  // These tags will be attached only to this call to the LLM.\n  tags: [\"example\", \"callbacks\", \"request\"],\n  // This handler will be used only for this call.\n  callbacks: [new ConsoleCallbackHandler()],\n});\n\n\n\n\nAPI REFERENCE:\n\n * ConsoleCallbackHandler [/docs/api/callbacks/classes/ConsoleCallbackHandler] from langchain/callbacks\n * OpenAI [/docs/api/llms_openai/classes/OpenAI] from langchain/llms/openai\n\n\nVERBOSE MODE\n\nThe verbose argument is available on most objects throughout the API (Chains, Models, Tools, Agents, etc.) as a constructor\nargument, eg. new LLMChain({ verbose: true }), and it is equivalent to passing a ConsoleCallbackHandler to the callbacks argument\nof that object and all child objects. This is useful for debugging, as it will log all events to the console. You can also enable\nverbose mode for the entire application by setting the environment variable LANGCHAIN_VERBOSE=true.\n\nimport { PromptTemplate } from \"langchain/prompts\";\nimport { LLMChain } from \"langchain/chains\";\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst chain = new LLMChain({\n  llm: new OpenAI({ temperature: 0 }),\n  prompt: PromptTemplate.fromTemplate(\"Hello, world!\"),\n  // This will enable logging of all Chain *and* LLM events to the console.\n  verbose: true,\n});\n\n\n\n\nAPI REFERENCE:\n\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * LLMChain [/docs/api/chains/classes/LLMChain] from langchain/chains\n * OpenAI [/docs/api/llms_openai/classes/OpenAI] from langchain/llms/openai\n\n\nWHEN DO YOU WANT TO USE EACH OF THESE?\n\n * Constructor callbacks are most useful for use cases such as logging, monitoring, etc., which are not specific to a single\n   request, but rather to the entire chain. For example, if you want to log all the requests made to an LLMChain, you would pass a\n   handler to the constructor.\n * Request callbacks are most useful for use cases such as streaming, where you want to stream the output of a single request to a\n   specific websocket connection, or other similar use cases. For example, if you want to stream the output of a single request to\n   a websocket, you would pass a handler to the call() method\n\n\nUSAGE EXAMPLES\n\n\nBUILT-IN HANDLERS\n\nLangChain provides a few built-in handlers that you can use to get started. These are available in the langchain/callbacks module.\nThe most basic handler is the ConsoleCallbackHandler, which simply logs all events to the console. In the future we will add more\ndefault handlers to the library. Note that when the verbose flag on the object is set to true, the ConsoleCallbackHandler will be\ninvoked even without being explicitly passed in.\n\nimport { ConsoleCallbackHandler } from \"langchain/callbacks\";\nimport { LLMChain } from \"langchain/chains\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\nexport const run = async () => {\n  const handler = new ConsoleCallbackHandler();\n  const llm = new OpenAI({ temperature: 0, callbacks: [handler] });\n  const prompt = PromptTemplate.fromTemplate(\"1 + {number} =\");\n  const chain = new LLMChain({ prompt, llm, callbacks: [handler] });\n\n  const output = await chain.call({ number: 2 });\n  /*\n  Entering new llm_chain chain...\n  Finished chain.\n  */\n\n  console.log(output);\n  /*\n  { text: ' 3\\n\\n3 - 1 = 2' }\n   */\n\n  // The non-enumerable key `__run` contains the runId.\n  console.log(output.__run);\n  /*\n  { runId: '90e1f42c-7cb4-484c-bf7a-70b73ef8e64b' }\n  */\n};\n\n\n\n\nAPI REFERENCE:\n\n * ConsoleCallbackHandler [/docs/api/callbacks/classes/ConsoleCallbackHandler] from langchain/callbacks\n * LLMChain [/docs/api/chains/classes/LLMChain] from langchain/chains\n * OpenAI [/docs/api/llms_openai/classes/OpenAI] from langchain/llms/openai\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n\n\nONE-OFF HANDLERS\n\nYou can create a one-off handler inline by passing a plain object to the callbacks argument. This object should implement the\nCallbackHandlerMethods [/docs/api/callbacks/interfaces/CallbackHandlerMethods] interface. This is useful if eg. you need to create\na handler that you will use only for a single request, eg to stream the output of an LLM/Agent/etc to a websocket.\n\nimport { OpenAI } from \"langchain/llms/openai\";\n\n// To enable streaming, we pass in `streaming: true` to the LLM constructor.\n// Additionally, we pass in a handler for the `handleLLMNewToken` event.\nconst model = new OpenAI({\n  maxTokens: 25,\n  streaming: true,\n});\n\nconst response = await model.call(\"Tell me a joke.\", {\n  callbacks: [\n    {\n      handleLLMNewToken(token: string) {\n        console.log({ token });\n      },\n    },\n  ],\n});\nconsole.log(response);\n/*\n{ token: '\\n' }\n{ token: '\\n' }\n{ token: 'Q' }\n{ token: ':' }\n{ token: ' Why' }\n{ token: ' did' }\n{ token: ' the' }\n{ token: ' chicken' }\n{ token: ' cross' }\n{ token: ' the' }\n{ token: ' playground' }\n{ token: '?' }\n{ token: '\\n' }\n{ token: 'A' }\n{ token: ':' }\n{ token: ' To' }\n{ token: ' get' }\n{ token: ' to' }\n{ token: ' the' }\n{ token: ' other' }\n{ token: ' slide' }\n{ token: '.' }\n\n\nQ: Why did the chicken cross the playground?\nA: To get to the other slide.\n*/\n\n\n\n\nAPI REFERENCE:\n\n * OpenAI [/docs/api/llms_openai/classes/OpenAI] from langchain/llms/openai\n\n\nMULTIPLE HANDLERS\n\nWe offer a method on the CallbackManager class that allows you to create a one-off handler. This is useful if eg. you need to\ncreate a handler that you will use only for a single request, eg to stream the output of an LLM/Agent/etc to a websocket.\n\nThis is a more complete example that passes a CallbackManager to a ChatModel, and LLMChain, a Tool, and an Agent.\n\nimport { LLMChain } from \"langchain/chains\";\nimport { AgentExecutor, ZeroShotAgent } from \"langchain/agents\";\nimport { BaseCallbackHandler } from \"langchain/callbacks\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { Calculator } from \"langchain/tools/calculator\";\nimport { AgentAction } from \"langchain/schema\";\nimport { Serialized } from \"langchain/load/serializable\";\n\nexport const run = async () => {\n  // You can implement your own callback handler by extending BaseCallbackHandler\n  class CustomHandler extends BaseCallbackHandler {\n    name = \"custom_handler\";\n\n    handleLLMNewToken(token: string) {\n      console.log(\"token\", { token });\n    }\n\n    handleLLMStart(llm: Serialized, _prompts: string[]) {\n      console.log(\"handleLLMStart\", { llm });\n    }\n\n    handleChainStart(chain: Serialized) {\n      console.log(\"handleChainStart\", { chain });\n    }\n\n    handleAgentAction(action: AgentAction) {\n      console.log(\"handleAgentAction\", action);\n    }\n\n    handleToolStart(tool: Serialized) {\n      console.log(\"handleToolStart\", { tool });\n    }\n  }\n\n  const handler1 = new CustomHandler();\n\n  // Additionally, you can use the `fromMethods` method to create a callback handler\n  const handler2 = BaseCallbackHandler.fromMethods({\n    handleLLMStart(llm, _prompts: string[]) {\n      console.log(\"handleLLMStart: I'm the second handler!!\", { llm });\n    },\n    handleChainStart(chain) {\n      console.log(\"handleChainStart: I'm the second handler!!\", { chain });\n    },\n    handleAgentAction(action) {\n      console.log(\"handleAgentAction\", action);\n    },\n    handleToolStart(tool) {\n      console.log(\"handleToolStart\", { tool });\n    },\n  });\n\n  // You can restrict callbacks to a particular object by passing it upon creation\n  const model = new ChatOpenAI({\n    temperature: 0,\n    callbacks: [handler2], // this will issue handler2 callbacks related to this model\n    streaming: true, // needed to enable streaming, which enables handleLLMNewToken\n  });\n\n  const tools = [new Calculator()];\n  const agentPrompt = ZeroShotAgent.createPrompt(tools);\n\n  const llmChain = new LLMChain({\n    llm: model,\n    prompt: agentPrompt,\n    callbacks: [handler2], // this will issue handler2 callbacks related to this chain\n  });\n  const agent = new ZeroShotAgent({\n    llmChain,\n    allowedTools: [\"search\"],\n  });\n\n  const agentExecutor = AgentExecutor.fromAgentAndTools({\n    agent,\n    tools,\n  });\n\n  /*\n   * When we pass the callback handler to the agent executor, it will be used for all\n   * callbacks related to the agent and all the objects involved in the agent's\n   * execution, in this case, the Tool, LLMChain, and LLM.\n   *\n   * The `handler2` callback handler will only be used for callbacks related to the\n   * LLMChain and LLM, since we passed it to the LLMChain and LLM objects upon creation.\n   */\n  const result = await agentExecutor.call(\n    {\n      input: \"What is 2 to the power of 8\",\n    },\n    [handler1]\n  ); // this is needed to see handleAgentAction\n  /*\n  handleChainStart { chain: { name: 'agent_executor' } }\n  handleChainStart { chain: { name: 'llm_chain' } }\n  handleChainStart: I'm the second handler!! { chain: { name: 'llm_chain' } }\n  handleLLMStart { llm: { name: 'openai' } }\n  handleLLMStart: I'm the second handler!! { llm: { name: 'openai' } }\n  token { token: '' }\n  token { token: 'I' }\n  token { token: ' can' }\n  token { token: ' use' }\n  token { token: ' the' }\n  token { token: ' calculator' }\n  token { token: ' tool' }\n  token { token: ' to' }\n  token { token: ' solve' }\n  token { token: ' this' }\n  token { token: '.\\n' }\n  token { token: 'Action' }\n  token { token: ':' }\n  token { token: ' calculator' }\n  token { token: '\\n' }\n  token { token: 'Action' }\n  token { token: ' Input' }\n  token { token: ':' }\n  token { token: ' ' }\n  token { token: '2' }\n  token { token: '^' }\n  token { token: '8' }\n  token { token: '' }\n  handleAgentAction {\n    tool: 'calculator',\n    toolInput: '2^8',\n    log: 'I can use the calculator tool to solve this.\\n' +\n      'Action: calculator\\n' +\n      'Action Input: 2^8'\n  }\n  handleToolStart { tool: { name: 'calculator' } }\n  handleChainStart { chain: { name: 'llm_chain' } }\n  handleChainStart: I'm the second handler!! { chain: { name: 'llm_chain' } }\n  handleLLMStart { llm: { name: 'openai' } }\n  handleLLMStart: I'm the second handler!! { llm: { name: 'openai' } }\n  token { token: '' }\n  token { token: 'That' }\n  token { token: ' was' }\n  token { token: ' easy' }\n  token { token: '!\\n' }\n  token { token: 'Final' }\n  token { token: ' Answer' }\n  token { token: ':' }\n  token { token: ' ' }\n  token { token: '256' }\n  token { token: '' }\n  */\n\n  console.log(result);\n  /*\n  {\n    output: '256',\n    __run: { runId: '26d481a6-4410-4f39-b74d-f9a4f572379a' }\n  }\n  */\n};\n\n\n\n\nAPI REFERENCE:\n\n * LLMChain [/docs/api/chains/classes/LLMChain] from langchain/chains\n * AgentExecutor [/docs/api/agents/classes/AgentExecutor] from langchain/agents\n * ZeroShotAgent [/docs/api/agents/classes/ZeroShotAgent] from langchain/agents\n * BaseCallbackHandler [/docs/api/callbacks/classes/BaseCallbackHandler] from langchain/callbacks\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n * Calculator [/docs/api/tools_calculator/classes/Calculator] from langchain/tools/calculator\n * AgentAction [/docs/api/schema/types/AgentAction] from langchain/schema\n * Serialized [/docs/api/load_serializable/types/Serialized] from langchain/load/serializable\n\nPrevious\nVectorStore Agent Toolkit\n[/docs/modules/agents/toolkits/vectorstore]\nNext\nBackgrounding callbacks\n[/docs/modules/callbacks/how_to/background_callbacks]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.",
		metadata: {
			source: 'https://js.langchain.com/docs/modules/callbacks/',
			title: 'Callbacks | ü¶úÔ∏èüîó Langchain',
			description:
				'LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * LangChain Expression Language\n\n\nLANGCHAIN EXPRESSION LANGUAGE (LCEL)\n\nLangChain Expression Language or LCEL is a declarative way to easily compose chains together. Any chain constructed this way will\nautomatically have full sync, async, and streaming support.\n\nINTERFACE [/docs/expression_language/interface]\n\nThe base interface shared by all LCEL objects\n\nCOOKBOOK [/docs/expression_language/cookbook]\n\nExamples of common LCEL usage patterns\n\nYou can also peruse this high-level overview/cheatsheet made by @zhanghaili0610 [https://twitter.com/zhanghaili0610]:\n\n[/assets/images/langchain-js-runnable-cheatsheet-17e8dcc53c6636dd6f3fad0fbdb65115.png]\n\nPrevious\nModules\n[/docs/modules/]\nNext\nRoute between multiple runnables\n[/docs/expression_language/how_to/routing]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/expression_language/',
			title: 'LangChain Expression Language (LCEL) | ü¶úÔ∏èüîó Langchain',
			description:
				'LangChain Expression Language or LCEL is a declarative way to easily compose chains together.',
			language: 'en'
		}
	},
	{
		pageContent:
			"Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n     * Route between multiple runnables [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * LangChain Expression Language [/docs/expression_language/]\n * How to\n * Route between multiple runnables\n\nOn this page\n\n\nROUTE BETWEEN MULTIPLE RUNNABLES\n\nThis notebook covers how to do routing in the LangChain Expression Language.\n\nRouting allows you to create non-deterministic chains where the output of a previous step defines the next step. Routing helps\nprovide structure and consistency around interactions with LLMs.\n\nThere are two ways to perform routing:\n\n 1. Using a RunnableBranch.\n 2. Writing custom factory function that takes the input of a previous step and returns a runnable. Importantly, this should\n    return a runnable and NOT actually execute.\n\nWe'll illustrate both methods using a two step sequence where the first step classifies an input question as being about\nLangChain, Anthropic, or Other, then routes to a corresponding prompt chain.\n\n\nUSING A RUNNABLEBRANCH\n\nA RunnableBranch is initialized with a list of (condition, runnable) pairs and a default runnable. It selects which branch by\npassing each condition the input it's invoked with. It selects the first condition to evaluate to True, and runs the corresponding\nrunnable to that condition with the input.\n\nIf no provided conditions match, it runs the default runnable.\n\nHere's an example of what it looks like in action:\n\nimport { ChatAnthropic } from \"langchain/chat_models/anthropic\";\nimport { PromptTemplate } from \"langchain/prompts\";\nimport { StringOutputParser } from \"langchain/schema/output_parser\";\nimport { RunnableBranch, RunnableSequence } from \"langchain/schema/runnable\";\n\nconst promptTemplate =\n  PromptTemplate.fromTemplate(`Given the user question below, classify it as either being about \\`LangChain\\`, \\`Anthropic\\`, or \\`Other\\`.\n                                     \nDo not respond with more than one word.\n\n<question>\n{question}\n</question>\n\nClassification:`);\n\nconst model = new ChatAnthropic({\n  modelName: \"claude-2\",\n});\n\nconst classificationChain = RunnableSequence.from([\n  promptTemplate,\n  model,\n  new StringOutputParser(),\n]);\n\nconst classificationChainResult = await classificationChain.invoke({\n  question: \"how do I call Anthropic?\",\n});\nconsole.log(classificationChainResult);\n\n/*\n  Anthropic\n*/\n\nconst langChainChain = PromptTemplate.fromTemplate(\n  `You are an expert in langchain.\nAlways answer questions starting with \"As Harrison Chase told me\".\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst anthropicChain = PromptTemplate.fromTemplate(\n  `You are an expert in anthropic. \\\nAlways answer questions starting with \"As Dario Amodei told me\". \\\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst generalChain = PromptTemplate.fromTemplate(\n  `Respond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst branch = RunnableBranch.from([\n  [\n    (x: { topic: string; question: string }) =>\n      x.topic.toLowerCase().includes(\"anthropic\"),\n    anthropicChain,\n  ],\n  [\n    (x: { topic: string; question: string }) =>\n      x.topic.toLowerCase().includes(\"langchain\"),\n    langChainChain,\n  ],\n  generalChain,\n]);\n\nconst fullChain = RunnableSequence.from([\n  {\n    topic: classificationChain,\n    question: (input: { question: string }) => input.question,\n  },\n  branch,\n]);\n\nconst result1 = await fullChain.invoke({\n  question: \"how do I use Anthropic?\",\n});\n\nconsole.log(result1);\n\n/*\n  AIMessage {\n    content: ' As Dario Amodei told me, here are some tips for how to use Anthropic:\\n' +\n      '\\n' +\n      \"First, sign up for an account on Anthropic's website. This will give you access to their conversational AI assistant named Claude. \\n\" +\n      '\\n' +\n      \"Once you've created an account, you can have conversations with Claude through their web interface. Talk to Claude like you would talk to a person, asking questions, giving instructions, etc. Claude is trained to have natural conversations and be helpful.\\n\" +\n      '\\n' +\n      \"You can also integrate Claude into your own applications using Anthropic's API. This allows you to build Claude's conversational abilities into chatbots, virtual assistants, and other AI systems you develop.\\n\" +\n      '\\n' +\n      'Anthropic is constantly working on improving Claude, so its capabilities are always expanding. Make sure to check their blog and documentation to stay up to date on the latest features.\\n' +\n      '\\n' +\n      'The key is to interact with Claude regularly so it can learn from you. The more you chat with it, the better it will become at understanding you and having personalized conversations. Over time, Claude will feel more human-like as it accumulates more conversational experience.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result2 = await fullChain.invoke({\n  question: \"how do I use LangChain?\",\n});\n\nconsole.log(result2);\n\n/*\n  AIMessage {\n    content: ' As Harrison Chase told me, here is how you use LangChain:\\n' +\n      '\\n' +\n      'First, think carefully about what you want to ask or have the AI do. Frame your request clearly and specifically. Avoid vague or overly broad prompts that could lead to unhelpful or concerning responses. \\n' +\n      '\\n' +\n      'Next, type your question or request into the chat window and send it. Be patient as the AI processes your input and generates a response. The AI will do its best to provide a helpful answer or follow your instructions, but its capabilities are limited.\\n' +\n      '\\n' +\n      'Keep your requests simple at first. Ask basic questions or have the AI summarize content or generate basic text. As you get more comfortable, you can try having the AI perform more complex tasks like answering tricky questions, generating stories, or having a conversation.\\n' +\n      '\\n' +\n      \"Pay attention to the AI's responses. If they seem off topic, nonsensical, or concerning, rephrase your prompt to steer the AI in a better direction. You may need to provide additional clarification or context to get useful results.\\n\" +\n      '\\n' +\n      'Be polite and respectful towards the AI system. Remember, it is a tool designed to be helpful, harmless, and honest. Do not try to trick, confuse, or exploit it. \\n' +\n      '\\n' +\n      'I hope these tips help you have a safe, fun and productive experience using LangChain! Let me know if you have any other questions.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result3 = await fullChain.invoke({\n  question: \"what is 2 + 2?\",\n});\n\nconsole.log(result3);\n\n/*\n  AIMessage {\n    content: ' 4',\n    additional_kwargs: {}\n  }\n*/\n\n\n\n\nAPI REFERENCE:\n\n * ChatAnthropic [/docs/api/chat_models_anthropic/classes/ChatAnthropic] from langchain/chat_models/anthropic\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * StringOutputParser [/docs/api/schema_output_parser/classes/StringOutputParser] from langchain/schema/output_parser\n * RunnableBranch [/docs/api/schema_runnable/classes/RunnableBranch] from langchain/schema/runnable\n * RunnableSequence [/docs/api/schema_runnable/classes/RunnableSequence] from langchain/schema/runnable\n\n\nUSING A CUSTOM FUNCTION\n\nYou can also use a custom function to route between different outputs. Here's an example:\n\nimport { ChatAnthropic } from \"langchain/chat_models/anthropic\";\nimport { PromptTemplate } from \"langchain/prompts\";\nimport { StringOutputParser } from \"langchain/schema/output_parser\";\nimport { RunnableLambda, RunnableSequence } from \"langchain/schema/runnable\";\n\nconst promptTemplate =\n  PromptTemplate.fromTemplate(`Given the user question below, classify it as either being about \\`LangChain\\`, \\`Anthropic\\`, or \\`Other\\`.\n                                     \nDo not respond with more than one word.\n\n<question>\n{question}\n</question>\n\nClassification:`);\n\nconst model = new ChatAnthropic({\n  modelName: \"claude-2\",\n});\n\nconst classificationChain = RunnableSequence.from([\n  promptTemplate,\n  model,\n  new StringOutputParser(),\n]);\n\nconst classificationChainResult = await classificationChain.invoke({\n  question: \"how do I call Anthropic?\",\n});\nconsole.log(classificationChainResult);\n\n/*\n  Anthropic\n*/\n\nconst langChainChain = PromptTemplate.fromTemplate(\n  `You are an expert in langchain.\nAlways answer questions starting with \"As Harrison Chase told me\".\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst anthropicChain = PromptTemplate.fromTemplate(\n  `You are an expert in anthropic. \\\nAlways answer questions starting with \"As Dario Amodei told me\". \\\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst generalChain = PromptTemplate.fromTemplate(\n  `Respond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst route = ({ topic }: { input: string; topic: string }) => {\n  if (topic.toLowerCase().includes(\"anthropic\")) {\n    return anthropicChain;\n  } else if (topic.toLowerCase().includes(\"langchain\")) {\n    return langChainChain;\n  } else {\n    return generalChain;\n  }\n};\n\nconst fullChain = RunnableSequence.from([\n  {\n    topic: classificationChain,\n    question: (input: { question: string }) => input.question,\n  },\n  route,\n]);\n\nconst result1 = await fullChain.invoke({\n  question: \"how do I use Anthropic?\",\n});\n\nconsole.log(result1);\n\n/*\n  AIMessage {\n    content: ' As Dario Amodei told me, here are some tips for how to use Anthropic:\\n' +\n      '\\n' +\n      \"First, sign up for an account on Anthropic's website. This will give you access to their conversational AI assistant named Claude. \\n\" +\n      '\\n' +\n      \"Once you've created an account, you can have conversations with Claude through their web interface. Talk to Claude like you would talk to a person, asking questions, giving instructions, etc. Claude is trained to have natural conversations and be helpful.\\n\" +\n      '\\n' +\n      \"You can also integrate Claude into your own applications using Anthropic's API. This allows you to build Claude's conversational abilities into chatbots, virtual assistants, and other AI systems you develop.\\n\" +\n      '\\n' +\n      'Anthropic is constantly working on improving Claude, so its capabilities are always expanding. Make sure to check their blog and documentation to stay up to date on the latest features.\\n' +\n      '\\n' +\n      'The key is to interact with Claude regularly so it can learn from you. The more you chat with it, the better it will become at understanding you and having personalized conversations. Over time, Claude will feel more human-like as it accumulates more conversational experience.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result2 = await fullChain.invoke({\n  question: \"how do I use LangChain?\",\n});\n\nconsole.log(result2);\n\n/*\n  AIMessage {\n    content: ' As Harrison Chase told me, here is how you use LangChain:\\n' +\n      '\\n' +\n      'First, think carefully about what you want to ask or have the AI do. Frame your request clearly and specifically. Avoid vague or overly broad prompts that could lead to unhelpful or concerning responses. \\n' +\n      '\\n' +\n      'Next, type your question or request into the chat window and send it. Be patient as the AI processes your input and generates a response. The AI will do its best to provide a helpful answer or follow your instructions, but its capabilities are limited.\\n' +\n      '\\n' +\n      'Keep your requests simple at first. Ask basic questions or have the AI summarize content or generate basic text. As you get more comfortable, you can try having the AI perform more complex tasks like answering tricky questions, generating stories, or having a conversation.\\n' +\n      '\\n' +\n      \"Pay attention to the AI's responses. If they seem off topic, nonsensical, or concerning, rephrase your prompt to steer the AI in a better direction. You may need to provide additional clarification or context to get useful results.\\n\" +\n      '\\n' +\n      'Be polite and respectful towards the AI system. Remember, it is a tool designed to be helpful, harmless, and honest. Do not try to trick, confuse, or exploit it. \\n' +\n      '\\n' +\n      'I hope these tips help you have a safe, fun and productive experience using LangChain! Let me know if you have any other questions.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result3 = await fullChain.invoke({\n  question: \"what is 2 + 2?\",\n});\n\nconsole.log(result3);\n\n/*\n  AIMessage {\n    content: ' 4',\n    additional_kwargs: {}\n  }\n*/\n\n\n\n\nAPI REFERENCE:\n\n * ChatAnthropic [/docs/api/chat_models_anthropic/classes/ChatAnthropic] from langchain/chat_models/anthropic\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * StringOutputParser [/docs/api/schema_output_parser/classes/StringOutputParser] from langchain/schema/output_parser\n * RunnableLambda [/docs/api/schema_runnable/classes/RunnableLambda] from langchain/schema/runnable\n * RunnableSequence [/docs/api/schema_runnable/classes/RunnableSequence] from langchain/schema/runnable\n\nPrevious\nLangChain Expression Language (LCEL)\n[/docs/expression_language/]\nNext\nCookbook\n[/docs/expression_language/cookbook/]\n * Using a RunnableBranch\n * Using a custom function\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.",
		metadata: {
			source: 'https://js.langchain.com/docs/expression_language/how_to/routing',
			title: 'Route between multiple runnables | ü¶úÔ∏èüîó Langchain',
			description: 'This notebook covers how to do routing in the LangChain Expression Language.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n     * Prompt + LLM [/docs/expression_language/cookbook/prompt_llm_parser]\n     * Retrieval augmented generation (RAG) [/docs/expression_language/cookbook/retrieval]\n     * Multiple chains [/docs/expression_language/cookbook/multiple_chains]\n     * Querying a SQL DB [/docs/expression_language/cookbook/sql_db]\n     * Adding memory [/docs/expression_language/cookbook/adding_memory]\n     * Using tools [/docs/expression_language/cookbook/tools]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * LangChain Expression Language [/docs/expression_language/]\n * Cookbook\n\n\nCOOKBOOK\n\nExample code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose\ndifferent Runnable (the core LCEL interface) components to achieve various tasks. If you\'re just getting acquainted with LCEL, the\nPrompt + LLM [/docs/expression_language/cookbook/prompt_llm_parser] page is a good place to start.\n\n\nüìÑÔ∏è PROMPT + LLM\n\nOne of the most foundational Expression Language compositions is taking:\n\n[/docs/expression_language/cookbook/prompt_llm_parser]\n\n\nüìÑÔ∏è RETRIEVAL AUGMENTED GENERATION (RAG)\n\nLet\'s now look at adding in a retrieval step to a prompt and an LLM, which adds up to a "retrieval-augmented generation" chain:\n\n[/docs/expression_language/cookbook/retrieval]\n\n\nüìÑÔ∏è MULTIPLE CHAINS\n\nRunnables can easily be used to combine multiple Chains:\n\n[/docs/expression_language/cookbook/multiple_chains]\n\n\nüìÑÔ∏è QUERYING A SQL DB\n\nWe can replicate our SQLDatabaseChain with Runnables.\n\n[/docs/expression_language/cookbook/sql_db]\n\n\nüìÑÔ∏è ADDING MEMORY\n\nThis shows how to add memory to an arbitrary chain. Right now, you can use the memory classes but need to hook them up manually.\n\n[/docs/expression_language/cookbook/adding_memory]\n\n\nüìÑÔ∏è USING TOOLS\n\nTools are also runnables, and can therefore be used within a chain:\n\n[/docs/expression_language/cookbook/tools]\nPrevious\nRoute between multiple runnables\n[/docs/expression_language/how_to/routing]\nNext\nPrompt + LLM\n[/docs/expression_language/cookbook/prompt_llm_parser]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/expression_language/cookbook/',
			title: 'Cookbook | ü¶úÔ∏èüîó Langchain',
			description:
				"Example code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the Prompt + LLM page is a good place to start.",
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * LangChain Expression Language [/docs/expression_language/]\n * Interface\n\nOn this page\n\n\nINTERFACE\n\nIn an effort to make it as easy as possible to create custom chains, we\'ve implemented a "Runnable"\n[/docs/api/schema_runnable/classes/Runnable] protocol that most components implement. This is a standard interface with a few\ndifferent methods, which make it easy to define custom chains as well as making it possible to invoke them in a standard way. The\nstandard interface exposed includes:\n\n * stream: stream back chunks of the response\n * invoke: call the chain on an input\n * batch: call the chain on a list of inputs\n\nThe type of the input varies by component. For a prompt it is an object, for a retriever it is a single string, for a model either\na single string, a list of chat messages, or a PromptValue.\n\nThe output type also varies by component. For an LLM it is a string, for a ChatModel it\'s a ChatMessage, for a prompt it\'s a\nPromptValue, and for a retriever it\'s a list of documents.\n\nYou can combine runnables (and runnable-like objects such as functions and objects whose values are all functions) into sequences\nin two ways:\n\n * Call the .pipe instance method, which takes another runnable-like as an argument\n * Use the RunnableSequence.from([]) static method with an array of runnable-likes, which will run in sequence when invoked\n\nSee below for examples of how this looks.\n\n\nSTREAM\n\nimport { PromptTemplate } from "langchain/prompts";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst model = new ChatOpenAI({});\nconst promptTemplate = PromptTemplate.fromTemplate(\n  "Tell me a joke about {topic}"\n);\n\nconst chain = promptTemplate.pipe(model);\n\nconst stream = await chain.stream({ topic: "bears" });\n\n// Each chunk has the same interface as a chat message\nfor await (const chunk of stream) {\n  console.log(chunk?.content);\n}\n\n/*\nWhy don\'t bears wear shoes?\n\nBecause they have bear feet!\n*/\n\n\n\n\nAPI REFERENCE:\n\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n\n\nINVOKE\n\nimport { PromptTemplate } from "langchain/prompts";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\nimport { RunnableSequence } from "langchain/schema/runnable";\n\nconst model = new ChatOpenAI({});\nconst promptTemplate = PromptTemplate.fromTemplate(\n  "Tell me a joke about {topic}"\n);\n\n// You can also create a chain using an array of runnables\nconst chain = RunnableSequence.from([promptTemplate, model]);\n\nconst result = await chain.invoke({ topic: "bears" });\n\nconsole.log(result);\n/*\n  AIMessage {\n    content: "Why don\'t bears wear shoes?\\n\\nBecause they have bear feet!",\n  }\n*/\n\n\n\n\nAPI REFERENCE:\n\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n * RunnableSequence [/docs/api/schema_runnable/classes/RunnableSequence] from langchain/schema/runnable\n\n\nBATCH\n\nimport { PromptTemplate } from "langchain/prompts";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst model = new ChatOpenAI({});\nconst promptTemplate = PromptTemplate.fromTemplate(\n  "Tell me a joke about {topic}"\n);\n\nconst chain = promptTemplate.pipe(model);\n\nconst result = await chain.batch([{ topic: "bears" }, { topic: "cats" }]);\n\nconsole.log(result);\n/*\n  [\n    AIMessage {\n      content: "Why don\'t bears wear shoes?\\n\\nBecause they have bear feet!",\n    },\n    AIMessage {\n      content: "Why don\'t cats play poker in the wild?\\n\\nToo many cheetahs!"\n    }\n  ]\n*/\n\n\n\n\nAPI REFERENCE:\n\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n\nYou can also pass a batchOptions argument to the call. There are options to set maximum concurrency and whether or not to return\nexceptions instead of throwing them (useful for gracefully handling failures!):\n\nimport { PromptTemplate } from "langchain/prompts";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst model = new ChatOpenAI({\n  modelName: "badmodel",\n});\nconst promptTemplate = PromptTemplate.fromTemplate(\n  "Tell me a joke about {topic}"\n);\n\nconst chain = promptTemplate.pipe(model);\n\nconst result = await chain.batch(\n  [{ topic: "bears" }, { topic: "cats" }],\n  {},\n  { returnExceptions: true, maxConcurrency: 1 }\n);\n\nconsole.log(result);\n/*\n  [\n    NotFoundError: The model `badmodel` does not exist\n      at Function.generate (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/error.ts:71:6)\n      at OpenAI.makeStatusError (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/core.ts:381:13)\n      at OpenAI.makeRequest (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/core.ts:442:15)\n      at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n      at async file:///Users/jacoblee/langchain/langchainjs/langchain/dist/chat_models/openai.js:514:29\n      at RetryOperation._fn (/Users/jacoblee/langchain/langchainjs/node_modules/p-retry/index.js:50:12) {\n    status: 404,\n    NotFoundError: The model `badmodel` does not exist\n        at Function.generate (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/error.ts:71:6)\n        at OpenAI.makeStatusError (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/core.ts:381:13)\n        at OpenAI.makeRequest (/Users/jacoblee/langchain/langchainjs/node_modules/openai/src/core.ts:442:15)\n        at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n        at async file:///Users/jacoblee/langchain/langchainjs/langchain/dist/chat_models/openai.js:514:29\n        at RetryOperation._fn (/Users/jacoblee/langchain/langchainjs/node_modules/p-retry/index.js:50:12) {\n      status: 404,\n  ]\n*/\n\n\n\n\nAPI REFERENCE:\n\n * PromptTemplate [/docs/api/prompts/classes/PromptTemplate] from langchain/prompts\n * ChatOpenAI [/docs/api/chat_models_openai/classes/ChatOpenAI] from langchain/chat_models/openai\n\nPrevious\nLangChain Expression Language (LCEL)\n[/docs/expression_language/]\nNext\nGuides\n[/docs/guides]\n * Stream\n * Invoke\n * Batch\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/expression_language/interface',
			title: 'Interface | ü¶úÔ∏èüîó Langchain',
			description:
				'In an effort to make it as easy as possible to create custom chains, we\'ve implemented a "Runnable" protocol that most components implement.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n   * Deployment [/docs/guides/deployment/]\n   * Evaluation [/docs/guides/evaluation/]\n   * Fallbacks [/docs/guides/fallbacks]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Guides\n\n\nGUIDES\n\nDesign guides for key parts of the development process\n\n\nüóÉÔ∏è DEPLOYMENT\n\n1 items\n\n[/docs/guides/deployment/]\n\n\nüóÉÔ∏è EVALUATION\n\n4 items\n\n[/docs/guides/evaluation/]\n\n\nüìÑÔ∏è FALLBACKS\n\nWhen working with language models, you may often encounter issues from the underlying APIs, e.g. rate limits or downtime.\n\n[/docs/guides/fallbacks]\nPrevious\nInterface\n[/docs/expression_language/interface]\nNext\nDeployment\n[/docs/guides/deployment/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/guides',
			title: 'Guides | ü¶úÔ∏èüîó Langchain',
			description: 'Design guides for key parts of the development process',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n   * Integrations [/docs/ecosystem/integrations/]\n   * LangSmith [https://docs.smith.langchain.com]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Ecosystem\n\n\nECOSYSTEM\n\n\nüóÉÔ∏è INTEGRATIONS\n\n4 items\n\n[/docs/ecosystem/integrations/]\n\n\nüîó LANGSMITH\n\n[https://docs.smith.langchain.com]\nPrevious\nFallbacks\n[/docs/guides/fallbacks]\nNext\nIntegrations\n[/docs/ecosystem/integrations/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/ecosystem',
			title: 'Ecosystem | ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n   * Scrimba interactive guides [/docs/additional_resources/scrimba]\n   * Gallery [https://github.com/kyrolabs/awesome-langchain]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Additional resources\n\n\nADDITIONAL RESOURCES\n\n\nüìÑÔ∏è SCRIMBA INTERACTIVE GUIDES\n\nScrimba is a code-learning platform that allows you to interactively edit and run\n\n[/docs/additional_resources/scrimba]\n\n\nüîó GALLERY\n\n[https://github.com/kyrolabs/awesome-langchain]\nPrevious\nUnstructured\n[/docs/ecosystem/integrations/unstructured]\nNext\nScrimba interactive guides\n[/docs/additional_resources/scrimba]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/additional_resources',
			title: 'Additional resources | ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Community navigator\n\n\nCOMMUNITY NAVIGATOR\n\nHi! Thanks for being here. We‚Äôre lucky to have a community of so many passionate developers building with LangChain‚Äìwe have so\nmuch to teach and learn from each other. Community members contribute code, host meetups, write blog posts, amplify each other‚Äôs\nwork, become each other\'s customers and collaborators, and so much more.\n\nWhether you‚Äôre new to LangChain, looking to go deeper, or just want to get more exposure to the world of building with LLMs, this\npage can point you in the right direction.\n\n * ü¶ú Contribute to LangChain\n\n * üåç¬†Meetups, Events, and Hackathons\n\n * üì£ Help Us Amplify Your Work\n\n * üí¨ Stay in the loop\n\n\nü¶ú CONTRIBUTE TO LANGCHAIN\n\nLangChain is the product of over 5,000+ contributions by 1,500+ contributors, and there is **still** so much to do together. Here\nare some ways to get involved:\n\n * Open a pull request [https://github.com/hwchase17/langchainjs/issues]: we‚Äôd appreciate all forms of contributions‚Äìnew features,\n   infrastructure improvements, better documentation, bug fixes, etc. If you have an improvement or an idea, we‚Äôd love to work on\n   it with you.\n * Read our contributor guidelines: [https://github.com/hwchase17/langchainjs/blob/main/CONTRIBUTING.md] We ask contributors to\n   follow a¬†"fork and pull request" [https://docs.github.com/en/get-started/quickstart/contributing-to-projects]¬†workflow, run a\n   few local checks for formatting, linting, and testing before submitting, and follow certain documentation and testing\n   conventions.\n * Become an expert: our experts help the community by answering product questions in Discord. If that‚Äôs a role you‚Äôd like to\n   play, we‚Äôd be so grateful! (And we have some special experts-only goodies/perks we can tell you more about). Send us an email\n   to introduce yourself at hello@langchain.dev [hello@langchain.dev] and we‚Äôll take it from there!\n * Integrate with LangChain: if your product integrates with LangChain‚Äìor aspires to‚Äìwe want to help make sure the experience is\n   as smooth as possible for you and end users. Send us an email at hello@langchain.dev [hello@langchain.dev] and tell us what\n   you‚Äôre working on.\n   * Become an Integration Maintainer: Partner with our team to ensure your integration stays up-to-date and talk directly with\n     users (and answer their inquiries) in our Discord. Introduce yourself at hello@langchain.dev [hello@langchain.dev] if you‚Äôd\n     like to explore this role.\n\n\nüåç MEETUPS, EVENTS, AND HACKATHONS\n\nOne of our favorite things about working in AI is how much enthusiasm there is for building together. We want to help make that as\neasy and impactful for you as possible!\n\n * Find a meetup, hackathon, or webinar: you can find the one for you on on our global events calendar\n   [https://mirror-feeling-d80.notion.site/0bc81da76a184297b86ca8fc782ee9a3?v=0d80342540df465396546976a50cfb3f].\n   * Submit an event to our calendar: email us at events@langchain.dev [events@langchain.dev] with a link to your event page! We\n     can also help you spread the word with our local communities.\n * Host a meetup: If you want to bring a group of builders together, we want to help! We can publicize your event on our event\n   calendar/Twitter, share with our local communities in Discord, send swag, or potentially hook you up with a sponsor. Email us\n   at events@langchain.dev [events@langchain.dev] to tell us about your event!\n * Become a meetup sponsor: we often hear from groups of builders that want to get together, but are blocked or limited on some\n   dimension (space to host, budget for snacks, prizes to distribute, etc.). If you‚Äôd like to help, send us an email to\n   events@langchain.dev [events@langchain.dev] we can share more about how it works!\n * Speak at an event: meetup hosts are always looking for great speakers, presenters, and panelists. If you‚Äôd like to do that at\n   an event, send us an email to hello@langchain.dev [hello@langchain.dev] with more information about yourself, what you want to\n   talk about, and what city you‚Äôre based in and we‚Äôll try to match you with an upcoming event!\n * Tell us about your LLM community: If you host or participate in a community that would welcome support from LangChain and/or\n   our team, send us an email at hello@langchain.dev [hello@langchain.dev] and let us know how we can help.\n\n\nüì£¬†HELP US AMPLIFY YOUR WORK\n\nIf you‚Äôre working on something you‚Äôre proud of, and think the LangChain community would benefit from knowing about it, we want to\nhelp you show it off.\n\n * Post about your work and mention us: we love hanging out on Twitter to see what people in the space are talking about and\n   working on. If you tag @langchainai [https://twitter.com/LangChainAI], we‚Äôll almost certainly see it and can show you some\n   love.\n * Publish something on our blog: if you‚Äôre writing about your experience building with LangChain, we‚Äôd love to post (or\n   crosspost) it on our blog! E-mail hello@langchain.dev [hello@langchain.dev] with a draft of your post! Or even an idea for\n   something you want to write about.\n * Get your product onto our integrations hub [https://integrations.langchain.com/]: Many developers take advantage of our\n   seamless integrations with other products, and come to our integrations hub to find out who those are. If you want to get your\n   product up there, tell us about it (and how it works with LangChain) at hello@langchain.dev [hello@langchain.dev].\n\n\n‚òÄÔ∏è STAY IN THE LOOP\n\nHere‚Äôs where our team hangs out, talks shop, spotlights cool work, and shares what we‚Äôre up to. We‚Äôd love to see you there too.\n\n * Twitter [https://twitter.com/LangChainAI]: we post about what we‚Äôre working on and what cool things we‚Äôre seeing in the space.\n   If you tag @langchainai in your post, we‚Äôll almost certainly see it, and can snow you some love!\n * Discord [https://discord.gg/6adMQxSpJS]: connect with with >30k developers who are building with LangChain\n * GitHub [https://github.com/hwchase17/langchainjs]: open pull requests, contribute to a discussion, and/or contribute\n * Subscribe to our bi-weekly Release Notes [https://6w1pwbss0py.typeform.com/to/KjZB1auB]: a twice/month email roundup of the\n   coolest things going on in our orbit\n * Slack: if you‚Äôre building an application in production at your company, we‚Äôd love to get into a Slack channel together. Fill\n   out this form [https://airtable.com/appwQzlErAS2qiP0L/shrGtGaVBVAz7NcV2] and we‚Äôll get in touch about setting one up.\n\nPrevious\nScrimba interactive guides\n[/docs/additional_resources/scrimba]\nNext\nlangchain\n[/docs/api/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/community',
			title: 'Community navigator | ü¶úÔ∏èüîó Langchain',
			description:
				"Hi! Thanks for being here. We‚Äôre lucky to have a community of so many passionate developers building with LangChain‚Äìwe have so much to teach and learn from each other. Community members contribute code, host meetups, write blog posts, amplify each other‚Äôs work, become each other's customers and collaborators, and so much more.",
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Use cases [/docs/use_cases]\n   * QA and Chat over Documents [/docs/use_cases/question_answering/]\n   * Tabular Question Answering [/docs/use_cases/tabular]\n   * Interacting with APIs [/docs/use_cases/api]\n   * Summarization [/docs/use_cases/summarization]\n   * Agent Simulations [/docs/use_cases/agent_simulations/]\n   * Autonomous Agents [/docs/use_cases/autonomous_agents/]\n   * Chatbots [/docs/use_cases/chatbots]\n   * Extraction [/docs/use_cases/extraction]\n\n * /\n * Use cases\n\n\nUSE CASES\n\nWalkthroughs of common end-to-end use cases\n\n\nüóÉÔ∏è QA AND CHAT OVER DOCUMENTS\n\n2 items\n\n[/docs/use_cases/question_answering/]\n\n\nüìÑÔ∏è TABULAR QUESTION ANSWERING\n\nLots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables.\n\n[/docs/use_cases/tabular]\n\n\nüìÑÔ∏è INTERACTING WITH APIS\n\nLots of data and information is stored behind APIs.\n\n[/docs/use_cases/api]\n\n\nüìÑÔ∏è SUMMARIZATION\n\nA common use case is wanting to summarize long documents.\n\n[/docs/use_cases/summarization]\n\n\nüóÉÔ∏è AGENT SIMULATIONS\n\n1 items\n\n[/docs/use_cases/agent_simulations/]\n\n\nüóÉÔ∏è AUTONOMOUS AGENTS\n\n3 items\n\n[/docs/use_cases/autonomous_agents/]\n\n\nüìÑÔ∏è CHATBOTS\n\nLanguage models are good at producing text, which makes them ideal for creating chatbots.\n\n[/docs/use_cases/chatbots]\n\n\nüìÑÔ∏è EXTRACTION\n\nMost APIs and databases still deal with structured information. Therefore, in order to better work with those, it can be useful to\nextract structured information from text. Examples of this include:\n\n[/docs/use_cases/extraction]\nNext\nQA and Chat over Documents\n[/docs/use_cases/question_answering/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/use_cases/',
			title: 'Use cases | ü¶úÔ∏èüîó Langchain',
			description: 'Walkthroughs of common end-to-end use cases',
			language: 'en'
		}
	},
	{
		pageContent:
			"Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Use cases [/docs/use_cases]\n   * QA and Chat over Documents [/docs/use_cases/question_answering/]\n   * Tabular Question Answering [/docs/use_cases/tabular]\n   * Interacting with APIs [/docs/use_cases/api]\n   * Summarization [/docs/use_cases/summarization]\n   * Agent Simulations [/docs/use_cases/agent_simulations/]\n   * Autonomous Agents [/docs/use_cases/autonomous_agents/]\n   * Chatbots [/docs/use_cases/chatbots]\n   * Extraction [/docs/use_cases/extraction]\n\n * /\n * Use cases [/docs/use_cases]\n * Chatbots\n\n\nCHATBOTS\n\nLanguage models are good at producing text, which makes them ideal for creating chatbots. Aside from the base prompts/LLMs, an\nimportant concept to know for Chatbots is memory. Most chat based applications rely on remembering what happened in previous\ninteractions, which memory is designed to help with.\n\nYou might find the following pages interesting:\n\n * Memory concepts and examples [/docs/modules/memory/]: Explanation of key concepts related to memory along with how-to's and\n   examples.\n * Conversation Agent [/docs/modules/agents/agent_types/chat_conversation_agent]: A notebook walking through how to create an\n   agent optimized for conversation.\n\nPrevious\nBabyAGI\n[/docs/use_cases/autonomous_agents/baby_agi]\nNext\nExtraction\n[/docs/use_cases/extraction]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.",
		metadata: {
			source: 'https://js.langchain.com/docs/use_cases/chatbots/',
			title: 'Chatbots | ü¶úÔ∏èüîó Langchain',
			description:
				'Language models are good at producing text, which makes them ideal for creating chatbots.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Use cases [/docs/use_cases]\n   * QA and Chat over Documents [/docs/use_cases/question_answering/]\n     * Conversational Retrieval Agents [/docs/use_cases/question_answering/conversational_retrieval_agents]\n     * Use local LLMs [/docs/use_cases/question_answering/local_retrieval_qa]\n   * Tabular Question Answering [/docs/use_cases/tabular]\n   * Interacting with APIs [/docs/use_cases/api]\n   * Summarization [/docs/use_cases/summarization]\n   * Agent Simulations [/docs/use_cases/agent_simulations/]\n   * Autonomous Agents [/docs/use_cases/autonomous_agents/]\n   * Chatbots [/docs/use_cases/chatbots]\n   * Extraction [/docs/use_cases/extraction]\n\n * /\n * Use cases [/docs/use_cases]\n * QA and Chat over Documents\n\n\nQA AND CHAT OVER DOCUMENTS\n\nChat and Question-Answering (QA) over data are popular LLM use-cases.\n\ndata can include many things, including:\n\n * Unstructured data (e.g., PDFs)\n * Structured data (e.g., SQL)\n * Code (e.g., Python)\n\nBelow we will review Chat and QA on Unstructured data.\n\nintro.png [/assets/images/qa_intro-9b468dbffe1cbe7f0bd822b28648db9e.png]\n\nUnstructured data can be loaded from many sources.\n\nCheck out the document loader integrations here [/docs/modules/data_connection/document_loaders/] to browse the set of supported\nloaders.\n\nEach loader returns data as a LangChain Document.\n\nDocuments are turned into a Chat or QA app following the general steps below:\n\n * Splitting: Text splitters [/docs/modules/data_connection/document_transformers/] break Documents into splits of specified size\n * Storage: Storage (e.g., often a vectorstore [/docs/modules/data_connection/vectorstores/]) will house and often embed\n   [https://www.pinecone.io/learn/vector-embeddings/] the splits\n * Retrieval: The app retrieves splits from storage (e.g., often with similar embeddings\n   [https://www.pinecone.io/learn/k-nearest-neighbor/] to the input question)\n * Output: An LLM [/docs/modules/model_io/models/llms/] produces an answer using a prompt that includes the question and the\n   retrieved splits\n\nflow.jpeg [/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg]\n\n\nQUICKSTART\n\nLet\'s load this blog post [https://lilianweng.github.io/posts/2023-06-23-agent/] on agents as an example Document.\n\nWe\'ll have a QA app in a few lines of code.\n\nFirst, set environment variables and install packages required for the guide:\n\n> yarn add cheerio\n# Or load env vars in your preferred way:\n> export OPENAI_API_KEY="..."\n\n\n\n\n\n1. LOADING, SPLITTING, STORAGE\n\n\n1.1 GETTING STARTED\n\nSpecify a Document loader.\n\n// Document loader\nimport { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";\n\nconst loader = new CheerioWebBaseLoader(\n  "https://lilianweng.github.io/posts/2023-06-23-agent/"\n);\nconst data = await loader.load();\n\n\n\n\nSplit the Document into chunks for embedding and vector storage.\n\nimport { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\n\nconst textSplitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 0,\n});\n\nconst splitDocs = await textSplitter.splitDocuments(data);\n\n\n\n\nEmbed and store the splits in a vector database (for demo purposes we use an unoptimized, in-memory example but you can browse\nintegrations here [/docs/modules/data_connection/vectorstores/integrations/]):\n\nimport { OpenAIEmbeddings } from "langchain/embeddings/openai";\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\n\nconst embeddings = new OpenAIEmbeddings();\n\nconst vectorStore = await MemoryVectorStore.fromDocuments(splitDocs, embeddings);\n\n\n\n\nHere are the three pieces together:\n\nlc.png [/assets/images/qa_data_load-70fac3ea6593b986613784dc056df21a.png]\n\n\n1.2 GOING DEEPER\n\n1.2.1 INTEGRATIONS\n\nDocument Loaders\n\n * Browse document loader integrations here [/docs/modules/data_connection/document_loaders/].\n\n * See further documentation on loaders here [/docs/modules/data_connection/document_loaders/].\n\nDocument Transformers\n\n * All can ingest loaded Documents and process them (e.g., split).\n\n * See further documentation on transformers here [/docs/modules/data_connection/document_transformers/].\n\nVectorstores\n\n * Browse vectorstore integrations here [/docs/modules/data_connection/vectorstores/integrations/].\n\n * See further documentation on vectorstores here [/docs/modules/data_connection/vectorstores/].\n\n\n2. RETRIEVAL\n\n\n2.1 GETTING STARTED\n\nRetrieve relevant splits [https://www.pinecone.io/learn/what-is-similarity-search/] for any question using similarity_search.\n\nconst relevantDocs = await vectorStore.similaritySearch("What is task decomposition?");\n\nconsole.log(relevantDocs.length);\n\n// 4\n\n\n\n\n\n2.2 GOING DEEPER\n\n2.2.1 RETRIEVAL\n\nVectorstores are commonly used for retrieval.\n\nBut, they are not the only option.\n\nFor example, SVMs (see thread here [https://twitter.com/karpathy/status/1647025230546886658?s=20]) can also be used.\n\nLangChain has many retrievers and retrieval methods [/docs/modules/data_connection/retrievers/] including, but not limited to,\nvectorstores.\n\nAll retrievers implement some common methods, such as getRelevantDocuments().\n\n\n3. QA\n\n\n3.1 GETTING STARTED\n\nDistill the retrieved documents into an answer using an LLM (e.g., gpt-3.5-turbo) with RetrievalQA chain.\n\nimport { RetrievalQAChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });\nconst chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever());\n\nconst response = await chain.call({\n  query: "What is task decomposition?"\n});\nconsole.log(response);\n\n/*\n  {\n    text: \'Task decomposition refers to the process of breaking down a larger task into smaller, more manageable subgoals. By decomposing a task, it becomes easier for an agent or system to handle complex tasks efficiently. Task decomposition can be done through various methods such as using prompting or task-specific instructions, or through human inputs. It helps in planning and organizing the steps required to complete a task effectively.\'\n  }\n*/\n\n\n\n\n\n3.2 GOING DEEPER\n\n3.2.1 INTEGRATIONS\n\nLLMs\n\n * Browse LLM integrations and further documentation here [/docs/modules/model_io/models/].\n\n3.2.2 CUSTOMIZING THE PROMPT\n\nThe prompt in RetrievalQA chain can be customized as follows.\n\nimport { RetrievalQAChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\nimport { PromptTemplate } from "langchain/prompts";\n\nconst model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });\n\nconst template = `Use the following pieces of context to answer the question at the end.\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\nUse three sentences maximum and keep the answer as concise as possible.\nAlways say "thanks for asking!" at the end of the answer.\n{context}\nQuestion: {question}\nHelpful Answer:`;\n\nconst chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever(), {\n  prompt: PromptTemplate.fromTemplate(template),\n});\n\nconst response = await chain.call({\n  query: "What is task decomposition?"\n});\n\nconsole.log(response);\n\n/*\n  {\n    text: \'Task decomposition is the process of breaking down a large task into smaller, more manageable subgoals. This allows for efficient handling of complex tasks and aids in planning and organizing the steps needed to achieve the overall goal. Thanks for asking!\'\n  }\n*/\n\n\n\n\n3.2.3 RETURNING SOURCE DOCUMENTS\n\nThe full set of retrieved documents used for answer distillation can be returned using return_source_documents=True.\n\nimport { RetrievalQAChain } from "langchain/chains";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });\n\nconst chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever(), {\n  returnSourceDocuments: true\n});\n\nconst response = await chain.call({\n  query: "What is task decomposition?"\n});\n\nconsole.log(response.sourceDocuments[0]);\n\n/*\nDocument {\n  pageContent: \'Task decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\\\\n1.", "What are the subgoals for achieving XYZ?", (2) by using task-specific instructions; e.g. "Write a story outline." for writing a novel, or (3) with human inputs.\',\n  metadata: [Object]\n}\n*/\n\n\n\n\n3.2.4 CUSTOMIZING RETRIEVED DOCS IN THE LLM PROMPT\n\nRetrieved documents can be fed to an LLM for answer distillation in a few different ways.\n\nstuff, refine, and map-reduce chains for passing documents to an LLM prompt are well summarized here\n[/docs/modules/chains/document/].\n\nstuff is commonly used because it simply "stuffs" all retrieved documents into the prompt.\n\nThe loadQAChain [/docs/modules/chains/document/] methods are easy ways to pass documents to an LLM using these various approaches.\n\nimport { loadQAStuffChain } from "langchain/chains";\n\nconst stuffChain = loadQAStuffChain(model);\n\nconst stuffResult = await stuffChain.call({\n  input_documents: relevantDocs,\n  question: "What is task decomposition?",\n});\n\nconsole.log(stuffResult);\n/*\n{\n  text: \'Task decomposition is the process of breaking down a large task into smaller, more manageable subgoals or steps. This allows for efficient handling of complex tasks by focusing on one subgoal at a time. Task decomposition can be done through various methods such as using simple prompting, task-specific instructions, or human inputs.\'\n}\n*/\n\n\n\n\n\n4. CHAT\n\n\n4.1 GETTING STARTED\n\nTo keep chat history, we use a variant of the previous chain called a ConversationalRetrievalQAChain. First, specify a Memory\nbuffer to track the conversation inputs / outputs.\n\nimport { ConversationalRetrievalQAChain } from "langchain/chains";\nimport { BufferMemory } from "langchain/memory";\nimport { ChatOpenAI } from "langchain/chat_models/openai";\n\nconst memory = new BufferMemory({\n  memoryKey: "chat_history",\n  returnMessages: true,\n});\n\n\n\n\nNext, we initialize and call the chain:\n\nconst model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });\nconst chain = ConversationalRetrievalQAChain.fromLLM(model, vectorStore.asRetriever(), {\n  memory\n});\n\nconst result = await chain.call({\n  question: "What are some of the main ideas in self-reflection?"\n});\nconsole.log(result);\n\n/*\n{\n  text: \'Some main ideas in self-reflection include:\\n\' +\n    \'\\n\' +\n    \'1. Iterative Improvement: Self-reflection allows autonomous agents to improve by continuously refining past action decisions and correcting mistakes.\\n\' +\n    \'\\n\' +\n    \'2. Trial and Error: Self-reflection plays a crucial role in real-world tasks where trial and error are inevitable. It helps agents learn from failed trajectories and make adjustments for future actions.\\n\' +\n    \'\\n\' +\n    \'3. Constructive Criticism: Agents engage in constructive self-criticism of their big-picture behavior to identify areas for improvement.\\n\' +\n    \'\\n\' +\n    \'4. Decision and Strategy Refinement: Reflection on past decisions and strategies enables agents to refine their approach and make more informed choices.\\n\' +\n    \'\\n\' +\n    \'5. Efficiency and Optimization: Self-reflection encourages agents to be smart and efficient in their actions, aiming to complete tasks in the least number of steps.\\n\' +\n    \'\\n\' +\n    \'These ideas highlight the importance of self-reflection in enhancing performance and guiding future actions.\'\n}\n*/\n\n\n\n\nThe Memory buffer has context to resolve "it" ("self-reflection") in the below question.\n\nconst followupResult = await chain.call({\n  question: "How does the Reflexion paper handle it?"\n});\nconsole.log(followupResult);\n\n/*\n{\n  text: "The Reflexion paper introduces a framework that equips agents with dynamic memory and self-reflection capabilities to improve their reasoning skills. The approach involves showing the agent two-shot examples, where each example consists of a failed trajectory and an ideal reflection on how to guide future changes in the agent\'s plan. These reflections are then added to the agent\'s working memory as context for querying a language model. The agent uses this self-reflection information to make decisions on whether to start a new trial or continue with the current plan."\n}\n*/\n\n\n\n\n\n4.2 GOING DEEPER\n\nThe documentation [/docs/modules/chains/popular/chat_vector_db] on ConversationalRetrievalQAChain offers a few extensions, such as\nstreaming and source documents.\n\nPrevious\nUse cases\n[/docs/use_cases]\nNext\nConversational Retrieval Agents\n[/docs/use_cases/question_answering/conversational_retrieval_agents]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/use_cases/question_answering/',
			title: 'QA and Chat over Documents | ü¶úÔ∏èüîó Langchain',
			description: 'Chat and Question-Answering (QA) over data are popular LLM use-cases.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Use cases [/docs/use_cases]\n   * QA and Chat over Documents [/docs/use_cases/question_answering/]\n   * Tabular Question Answering [/docs/use_cases/tabular]\n   * Interacting with APIs [/docs/use_cases/api]\n   * Summarization [/docs/use_cases/summarization]\n   * Agent Simulations [/docs/use_cases/agent_simulations/]\n   * Autonomous Agents [/docs/use_cases/autonomous_agents/]\n   * Chatbots [/docs/use_cases/chatbots]\n   * Extraction [/docs/use_cases/extraction]\n\n * /\n * Use cases [/docs/use_cases]\n * Tabular Question Answering\n\n\nTABULAR QUESTION ANSWERING\n\nLots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables. This page covers all\nresources available in LangChain for working with data in this format.\n\n\nCHAINS\n\nIf you are just getting started, and you have relatively small/simple tabular data, you should get started with chains. Chains are\na sequence of predetermined steps, so they are good to get started with as they give you more control and let you understand what\nis happening better.\n\n * SQL Database Chain [/docs/modules/chains/popular/sqlite]\n\n\nAGENTS\n\nAgents are more complex, and involve multiple queries to the LLM to understand what to do. The downside of agents are that you\nhave less control. The upside is that they are more powerful, which allows you to use them on larger databases and more complex\nschemas.\n\n * SQL Agent [/docs/modules/agents/toolkits/sql]\n\nPrevious\nUse local LLMs\n[/docs/use_cases/question_answering/local_retrieval_qa]\nNext\nInteracting with APIs\n[/docs/use_cases/api]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/use_cases/tabular',
			title: 'Tabular Question Answering | ü¶úÔ∏èüîó Langchain',
			description:
				'Lots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables.',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n   * Deployment [/docs/guides/deployment/]\n   * Evaluation [/docs/guides/evaluation/]\n   * Fallbacks [/docs/guides/fallbacks]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Guides\n\n\nGUIDES\n\nDesign guides for key parts of the development process\n\n\nüóÉÔ∏è DEPLOYMENT\n\n1 items\n\n[/docs/guides/deployment/]\n\n\nüóÉÔ∏è EVALUATION\n\n4 items\n\n[/docs/guides/evaluation/]\n\n\nüìÑÔ∏è FALLBACKS\n\nWhen working with language models, you may often encounter issues from the underlying APIs, e.g. rate limits or downtime.\n\n[/docs/guides/fallbacks]\nPrevious\nInterface\n[/docs/expression_language/interface]\nNext\nDeployment\n[/docs/guides/deployment/]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/guides/',
			title: 'Guides | ü¶úÔ∏èüîó Langchain',
			description: 'Design guides for key parts of the development process',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n   * Scrimba interactive guides [/docs/additional_resources/scrimba]\n   * Gallery [https://github.com/kyrolabs/awesome-langchain]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Additional resources\n\n\nADDITIONAL RESOURCES\n\n\nüìÑÔ∏è SCRIMBA INTERACTIVE GUIDES\n\nScrimba is a code-learning platform that allows you to interactively edit and run\n\n[/docs/additional_resources/scrimba]\n\n\nüîó GALLERY\n\n[https://github.com/kyrolabs/awesome-langchain]\nPrevious\nUnstructured\n[/docs/ecosystem/integrations/unstructured]\nNext\nScrimba interactive guides\n[/docs/additional_resources/scrimba]\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/additional_resources/',
			title: 'Additional resources | ü¶úÔ∏èüîó Langchain',
			language: 'en'
		}
	},
	{
		pageContent:
			'Skip to main content\nü¶úÔ∏èüîó LangChain [/]Docs [/docs/get_started/introduction]Use cases [/docs/use_cases]API [/docs/api/]\nLangSmith [https://smith.langchain.com/]Python Docs\n[https://python.langchain.com/en/latest/]https://github.com/hwchase17/langchainjs\n\nCTRLK\n\n\n * Get started [/docs/get_started]\n   * Introduction [/docs/get_started/introduction]\n   * Installation [/docs/get_started/installation]\n   * Quickstart [/docs/get_started/quickstart]\n * Modules [/docs/modules/]\n   * Model I/ O [/docs/modules/model_io/]\n   * Retrieval [/docs/modules/data_connection/]\n   * Chains [/docs/modules/chains/]\n   * Memory [/docs/modules/memory/]\n   * Agents [/docs/modules/agents/]\n   * Callbacks [/docs/modules/callbacks/]\n   * Modules [/docs/modules/]\n * LangChain Expression Language [/docs/expression_language/]\n   * How to [/docs/expression_language/how_to/routing]\n   * Cookbook [/docs/expression_language/cookbook/]\n   * LangChain Expression Language (LCEL) [/docs/expression_language/]\n   * Interface [/docs/expression_language/interface]\n * Guides [/docs/guides]\n * Ecosystem [/docs/ecosystem]\n * Additional resources [/docs/additional_resources]\n   * Scrimba interactive guides [/docs/additional_resources/scrimba]\n   * Gallery [https://github.com/kyrolabs/awesome-langchain]\n * Community navigator [/docs/community]\n\n * ----------------------------------------------------------------------------------------------------------------------------------\n\n * API reference [/docs/api/]\n\n * /\n * Additional resources [/docs/additional_resources]\n * Scrimba interactive guides\n\nOn this page\n\n\nSCRIMBA INTERACTIVE GUIDES\n\nScrimba [https://scrimba.com] is a code-learning platform that allows you to interactively edit and run code while watching a\nvideo walkthrough.\n\nWe\'ve partnered with Scrimba on course materials (called "scrims") that teach the fundamentals of building with LangChain.js -\ncheck them out below, and check back for more as they become available!\n\n\nLANGCHAIN EXPRESSION LANGUAGE (LCEL)\n\n * The basics (PromptTemplate + LLM) [https://scrimba.com/scrim/c6rD6Nt9]\n\n\nDEEPER DIVES\n\n * Setting up a new PromptTemplate [https://scrimba.com/scrim/cbGwRwuV]\n * Setting up ChatOpenAI parameters [https://scrimba.com/scrim/cEgbBBUw]\n\nPrevious\nAdditional resources\n[/docs/additional_resources]\nNext\nCommunity navigator\n[/docs/community]\n * LangChain Expression Language (LCEL)\n * Deeper dives\n\nCommunity\n * Discord [https://discord.gg/cU2adEyC7w]\n * Twitter [https://twitter.com/LangChainAI]\n\nGitHub\n * Python [https://github.com/hwchase17/langchain]\n * JS/TS [https://github.com/hwchase17/langchainjs]\n\nMore\n * Homepage [https://langchain.com]\n * Blog [https://blog.langchain.dev]\n\nCopyright ¬© 2023 LangChain, Inc.',
		metadata: {
			source: 'https://js.langchain.com/docs/additional_resources/scrimba',
			title: 'Scrimba interactive guides | ü¶úÔ∏èüîó Langchain',
			description:
				'Scrimba is a code-learning platform that allows you to interactively edit and run',
			language: 'en'
		}
	}
];
